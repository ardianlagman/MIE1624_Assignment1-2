{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794772e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import learning_curve, ParameterGrid\n",
    "import statistics\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.formula.api as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c29da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('clean_kaggle_data_2020.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17edb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = pd.read_csv('clean_kaggle_data_2020.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acc29d",
   "metadata": {},
   "source": [
    "# Encoding and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c59322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10730, 357)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.shape #checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19692d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time from Start to Finish (seconds)</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7_Part_1</th>\n",
       "      <th>Q7_Part_2</th>\n",
       "      <th>Q7_Part_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35_B_Part_4</th>\n",
       "      <th>Q35_B_Part_5</th>\n",
       "      <th>Q35_B_Part_6</th>\n",
       "      <th>Q35_B_Part_7</th>\n",
       "      <th>Q35_B_Part_8</th>\n",
       "      <th>Q35_B_Part_9</th>\n",
       "      <th>Q35_B_Part_10</th>\n",
       "      <th>Q35_B_OTHER</th>\n",
       "      <th>Q24_Encoded</th>\n",
       "      <th>Q24_buckets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duration (in seconds)</td>\n",
       "      <td>What is your age (# years)?</td>\n",
       "      <td>What is your gender? - Selected Choice</td>\n",
       "      <td>In which country do you currently reside?</td>\n",
       "      <td>What is the highest level of formal education ...</td>\n",
       "      <td>Select the title most similar to your current ...</td>\n",
       "      <td>For how many years have you been writing code ...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289287</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100,000-124,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>860</td>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>10-20 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10,000-19,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>507</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SQL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>125,000-149,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>762</td>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SQL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70,000-79,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time from Start to Finish (seconds)                           Q1  \\\n",
       "0               Duration (in seconds)  What is your age (# years)?   \n",
       "1                              289287                        30-34   \n",
       "2                                 860                        35-39   \n",
       "3                                 507                        30-34   \n",
       "4                                 762                        35-39   \n",
       "\n",
       "                                       Q2  \\\n",
       "0  What is your gender? - Selected Choice   \n",
       "1                                     Man   \n",
       "2                                     Man   \n",
       "3                                     Man   \n",
       "4                                     Man   \n",
       "\n",
       "                                          Q3  \\\n",
       "0  In which country do you currently reside?   \n",
       "1                   United States of America   \n",
       "2                                  Argentina   \n",
       "3                   United States of America   \n",
       "4                                    Germany   \n",
       "\n",
       "                                                  Q4  \\\n",
       "0  What is the highest level of formal education ...   \n",
       "1                                    Master’s degree   \n",
       "2                                  Bachelor’s degree   \n",
       "3                                    Master’s degree   \n",
       "4                                    Doctoral degree   \n",
       "\n",
       "                                                  Q5  \\\n",
       "0  Select the title most similar to your current ...   \n",
       "1                                      Data Engineer   \n",
       "2                                  Software Engineer   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "\n",
       "                                                  Q6  \\\n",
       "0  For how many years have you been writing code ...   \n",
       "1                                         5-10 years   \n",
       "2                                        10-20 years   \n",
       "3                                         5-10 years   \n",
       "4                                         5-10 years   \n",
       "\n",
       "                                           Q7_Part_1  \\\n",
       "0  What programming languages do you use on a reg...   \n",
       "1                                             Python   \n",
       "2                                                NaN   \n",
       "3                                             Python   \n",
       "4                                             Python   \n",
       "\n",
       "                                           Q7_Part_2  \\\n",
       "0  What programming languages do you use on a reg...   \n",
       "1                                                  R   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           Q7_Part_3  ...  \\\n",
       "0  What programming languages do you use on a reg...  ...   \n",
       "1                                                SQL  ...   \n",
       "2                                                NaN  ...   \n",
       "3                                                SQL  ...   \n",
       "4                                                SQL  ...   \n",
       "\n",
       "                                        Q35_B_Part_4  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                        Q35_B_Part_5  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                        Q35_B_Part_6  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                        Q35_B_Part_7  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                        Q35_B_Part_8  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                        Q35_B_Part_9  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                       Q35_B_Part_10  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                NaN   \n",
       "2                                               None   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Q35_B_OTHER Q24_Encoded  \\\n",
       "0  In the next 2 years, do you hope to become mor...         NaN   \n",
       "1                                                NaN        10.0   \n",
       "2                                                NaN         1.0   \n",
       "3                                                NaN        11.0   \n",
       "4                                                NaN         7.0   \n",
       "\n",
       "       Q24_buckets  \n",
       "0              NaN  \n",
       "1  100,000-124,999  \n",
       "2    10,000-19,999  \n",
       "3  125,000-149,999  \n",
       "4    70,000-79,999  \n",
       "\n",
       "[5 rows x 357 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import_df.head() #seeing how the first rows look like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ca7055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n",
       "       'Q6', 'Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3',\n",
       "       ...\n",
       "       'Q35_B_Part_4', 'Q35_B_Part_5', 'Q35_B_Part_6', 'Q35_B_Part_7',\n",
       "       'Q35_B_Part_8', 'Q35_B_Part_9', 'Q35_B_Part_10', 'Q35_B_OTHER',\n",
       "       'Q24_Encoded', 'Q24_buckets'],\n",
       "      dtype='object', length=357)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05777586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time from Start to Finish (seconds)                                Duration (in seconds)\n",
       "Q1                                                           What is your age (# years)?\n",
       "Q2                                                What is your gender? - Selected Choice\n",
       "Q3                                             In which country do you currently reside?\n",
       "Q4                                     What is the highest level of formal education ...\n",
       "                                                             ...                        \n",
       "Q35_B_Part_9                           In the next 2 years, do you hope to become mor...\n",
       "Q35_B_Part_10                          In the next 2 years, do you hope to become mor...\n",
       "Q35_B_OTHER                            In the next 2 years, do you hope to become mor...\n",
       "Q24_Encoded                                                                          NaN\n",
       "Q24_buckets                                                                          NaN\n",
       "Name: 0, Length: 357, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.iloc[0] #checking the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26bc4af-c4cd-413e-8451-2bac0026100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-9,999            4441\n",
       "10,000-19,999      1114\n",
       "20,000-29,999       714\n",
       "100,000-124,999     573\n",
       "40,000-49,999       552\n",
       "30,000-39,999       540\n",
       "50,000-59,999       510\n",
       "60,000-69,999       408\n",
       "70,000-79,999       394\n",
       "150,000-199,999     347\n",
       "125,000-149,999     315\n",
       "90,000-99,999       280\n",
       "80,000-89,999       273\n",
       ">250,000            153\n",
       "200,000-249,999     115\n",
       "Name: Q24_buckets, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.Q24_buckets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b1cf04-8b72-4c57-9852-7c25a4a1bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: bucket 14 to correspone to > 250,000 will be treated as encoded label 13 because > 250,000 is no longer a defined range (compared to the rest of the encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff24ed6",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445e5863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Duration (in seconds)\n",
      "1 What is your age (# years)?\n",
      "2 What is your gender? - Selected Choice\n",
      "3 In which country do you currently reside?\n",
      "4 What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\n",
      "5 Select the title most similar to your current role (or most recent title if retired): - Selected Choice\n",
      "6 For how many years have you been writing code and/or programming?\n",
      "7 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python\n",
      "8 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - R\n",
      "9 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - SQL\n",
      "10 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - C\n",
      "11 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - C++\n",
      "12 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Java\n",
      "13 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Javascript\n",
      "14 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Julia\n",
      "15 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Swift\n",
      "16 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Bash\n",
      "17 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - MATLAB\n",
      "18 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - None\n",
      "19 What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "20 What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice\n",
      "21 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Jupyter (JupyterLab, Jupyter Notebooks, etc) \n",
      "22 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -  RStudio \n",
      "23 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -  Visual Studio / Visual Studio Code \n",
      "24 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Click to write Choice 13\n",
      "25 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -  PyCharm \n",
      "26 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Spyder  \n",
      "27 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Notepad++  \n",
      "28 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Sublime Text  \n",
      "29 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Vim / Emacs  \n",
      "30 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice -  MATLAB \n",
      "31 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - None\n",
      "32 Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "33 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Kaggle Notebooks\n",
      "34 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Colab Notebooks\n",
      "35 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Azure Notebooks\n",
      "36 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Paperspace / Gradient \n",
      "37 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Binder / JupyterHub \n",
      "38 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Code Ocean \n",
      "39 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  IBM Watson Studio \n",
      "40 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Amazon Sagemaker Studio \n",
      "41 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Amazon EMR Notebooks \n",
      "42 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Google Cloud AI Platform Notebooks \n",
      "43 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Google Cloud Datalab Notebooks\n",
      "44 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Databricks Collaborative Notebooks \n",
      "45 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - None\n",
      "46 Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "47 What type of computing platform do you use most often for your data science projects? - Selected Choice\n",
      "48 Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - GPUs\n",
      "49 Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - TPUs\n",
      "50 Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - None\n",
      "51 Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "52 Approximately how many times have you used a TPU (tensor processing unit)?\n",
      "53 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Matplotlib \n",
      "54 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Seaborn \n",
      "55 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Plotly / Plotly Express \n",
      "56 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Ggplot / ggplot2 \n",
      "57 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Shiny \n",
      "58 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  D3 js \n",
      "59 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Altair \n",
      "60 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Bokeh \n",
      "61 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Geoplotlib \n",
      "62 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Leaflet / Folium \n",
      "63 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice - None\n",
      "64 What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "65 For how many years have you used machine learning methods?\n",
      "66 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -   Scikit-learn \n",
      "67 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -   TensorFlow \n",
      "68 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  Keras \n",
      "69 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  PyTorch \n",
      "70 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  Fast.ai \n",
      "71 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  MXNet \n",
      "72 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  Xgboost \n",
      "73 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  LightGBM \n",
      "74 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  CatBoost \n",
      "75 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  Prophet \n",
      "76 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  H2O 3 \n",
      "77 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  Caret \n",
      "78 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  Tidymodels \n",
      "79 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -  JAX \n",
      "80 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice - None\n",
      "81 Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "82 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Linear or Logistic Regression\n",
      "83 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Decision Trees or Random Forests\n",
      "84 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Gradient Boosting Machines (xgboost, lightgbm, etc)\n",
      "85 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Bayesian Approaches\n",
      "86 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Evolutionary Approaches\n",
      "87 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Dense Neural Networks (MLPs, etc)\n",
      "88 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Convolutional Neural Networks\n",
      "89 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Generative Adversarial Networks\n",
      "90 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Recurrent Neural Networks\n",
      "91 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Transformer Networks (BERT, gpt-3, etc)\n",
      "92 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - None\n",
      "93 Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Other\n",
      "94 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - General purpose image/video tools (PIL, cv2, skimage, etc)\n",
      "95 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Image segmentation methods (U-Net, Mask R-CNN, etc)\n",
      "96 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Object detection methods (YOLOv3, RetinaNet, etc)\n",
      "97 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)\n",
      "98 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Generative Networks (GAN, VAE, etc)\n",
      "99 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - None\n",
      "100 Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "101 Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Word embeddings/vectors (GLoVe, fastText, word2vec)\n",
      "102 Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Encoder-decorder models (seq2seq, vanilla transformers)\n",
      "103 Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Contextualized embeddings (ELMo, CoVe)\n",
      "104 Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Transformer language models (GPT-3, BERT, XLnet, etc)\n",
      "105 Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - None\n",
      "106 Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "107 What is the size of the company where you are employed?\n",
      "108 Approximately how many individuals are responsible for data science workloads at your place of business?\n",
      "109 Does your current employer incorporate machine learning methods into their business?\n",
      "110 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Analyze and understand data to influence product or business decisions\n",
      "111 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\n",
      "112 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Build prototypes to explore applying machine learning to new areas\n",
      "113 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Build and/or run a machine learning service that operationally improves my product or workflows\n",
      "114 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Experimentation and iteration to improve existing ML models\n",
      "115 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Do research that advances the state of the art of machine learning\n",
      "116 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - None of these activities are an important part of my role at work\n",
      "117 Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Other\n",
      "118 What is your current yearly compensation (approximate $USD)?\n",
      "119 Approximately how much money have you (or your team) spent on machine learning and/or cloud computing services at home (or at work) in the past 5 years (approximate $USD)?\n",
      "120 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Amazon Web Services (AWS) \n",
      "121 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Microsoft Azure \n",
      "122 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Platform (GCP) \n",
      "123 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  IBM Cloud / Red Hat \n",
      "124 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Oracle Cloud \n",
      "125 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  SAP Cloud \n",
      "126 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Salesforce Cloud \n",
      "127 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  VMware Cloud \n",
      "128 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Alibaba Cloud \n",
      "129 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Tencent Cloud \n",
      "130 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice - None\n",
      "131 Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "132 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Amazon EC2 \n",
      "133 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  AWS Lambda \n",
      "134 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Amazon Elastic Container Service \n",
      "135 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Azure Cloud Services \n",
      "136 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Microsoft Azure Container Instances \n",
      "137 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Azure Functions \n",
      "138 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Compute Engine \n",
      "139 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Functions \n",
      "140 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Run \n",
      "141 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud App Engine \n",
      "142 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice - No / None\n",
      "143 Do you use any of the following cloud computing products on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "144 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Amazon SageMaker \n",
      "145 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Amazon Forecast \n",
      "146 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Amazon Rekognition \n",
      "147 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Azure Machine Learning Studio \n",
      "148 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Azure Cognitive Services \n",
      "149 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud AI Platform / Google Cloud ML Engine\n",
      "150 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Video AI \n",
      "151 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Natural Language \n",
      "152 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Vision AI \n",
      "153 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice - No / None\n",
      "154 Do you use any of the following machine learning products on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "155 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - MySQL \n",
      "156 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - PostgresSQL \n",
      "157 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - SQLite \n",
      "158 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Oracle Database \n",
      "159 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - MongoDB \n",
      "160 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Snowflake \n",
      "161 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - IBM Db2 \n",
      "162 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Microsoft SQL Server \n",
      "163 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Microsoft Access \n",
      "164 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Microsoft Azure Data Lake Storage \n",
      "165 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Amazon Redshift \n",
      "166 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Amazon Athena \n",
      "167 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Amazon DynamoDB \n",
      "168 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Google Cloud BigQuery \n",
      "169 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Google Cloud SQL \n",
      "170 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Google Cloud Firestore \n",
      "171 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - None\n",
      "172 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "173 Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often? - Selected Choice\n",
      "174 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Amazon QuickSight\n",
      "175 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Microsoft Power BI\n",
      "176 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Google Data Studio\n",
      "177 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Looker\n",
      "178 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Tableau\n",
      "179 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Salesforce\n",
      "180 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Einstein Analytics\n",
      "181 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Qlik\n",
      "182 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Domo\n",
      "183 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - TIBCO Spotfire\n",
      "184 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Alteryx \n",
      "185 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Sisense \n",
      "186 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - SAP Analytics Cloud \n",
      "187 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - None\n",
      "188 Which of the following business intelligence tools do you use on a regular basis? (Select all that apply) - Selected Choice - Other\n",
      "189 Which of the following business intelligence tools do you use most often? - Selected Choice\n",
      "190 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Automated data augmentation (e.g. imgaug, albumentations)\n",
      "191 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Automated feature engineering/selection (e.g. tpot, boruta_py)\n",
      "192 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Automated model selection (e.g. auto-sklearn, xcessiv)\n",
      "193 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Automated model architecture searches (e.g. darts, enas)\n",
      "194 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)\n",
      "195 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI)\n",
      "196 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - No / None\n",
      "197 Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "198 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -  Google Cloud AutoML \n",
      "199 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -  H20 Driverless AI  \n",
      "200 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -  Databricks AutoML \n",
      "201 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -  DataRobot AutoML \n",
      "202 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Tpot \n",
      "203 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Auto-Keras \n",
      "204 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Auto-Sklearn \n",
      "205 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Auto_ml \n",
      "206 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -   Xcessiv \n",
      "207 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -   MLbox \n",
      "208 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice - No / None\n",
      "209 Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\n",
      "210 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Neptune.ai \n",
      "211 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Weights & Biases \n",
      "212 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Comet.ml \n",
      "213 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Sacred + Omniboard \n",
      "214 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  TensorBoard \n",
      "215 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Guild.ai \n",
      "216 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Polyaxon \n",
      "217 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Trains \n",
      "218 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice -  Domino Model Monitor \n",
      "219 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice - No / None\n",
      "220 Do you use any tools to help manage machine learning experiments? (Select all that apply) - Selected Choice - Other\n",
      "221 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  Plotly Dash \n",
      "222 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  Streamlit \n",
      "223 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  NBViewer \n",
      "224 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  GitHub \n",
      "225 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  Personal blog \n",
      "226 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  Kaggle \n",
      "227 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  Colab \n",
      "228 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice -  Shiny \n",
      "229 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice - I do not share my work publicly\n",
      "230 Where do you publicly share or deploy your data analysis or machine learning applications? (Select all that apply) - Selected Choice - Other\n",
      "231 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Coursera\n",
      "232 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - edX\n",
      "233 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Kaggle Learn Courses\n",
      "234 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - DataCamp\n",
      "235 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Fast.ai\n",
      "236 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Udacity\n",
      "237 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Udemy\n",
      "238 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - LinkedIn Learning\n",
      "239 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Cloud-certification programs (direct from AWS, Azure, GCP, or similar)\n",
      "240 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - University Courses (resulting in a university degree)\n",
      "241 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - None\n",
      "242 On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Other\n",
      "243 What is the primary tool that you use at work or school to analyze data? (Include text response) - Selected Choice\n",
      "244 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Twitter (data science influencers)\n",
      "245 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Email newsletters (Data Elixir, O'Reilly Data & AI, etc)\n",
      "246 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Reddit (r/machinelearning, etc)\n",
      "247 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Kaggle (notebooks, forums, etc)\n",
      "248 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Course Forums (forums.fast.ai, Coursera forums, etc)\n",
      "249 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - YouTube (Kaggle YouTube, Cloud AI Adventures, etc)\n",
      "250 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Podcasts (Chai Time Data Science, O’Reilly Data Show, etc)\n",
      "251 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Blogs (Towards Data Science, Analytics Vidhya, etc)\n",
      "252 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Journal Publications (peer-reviewed journals, conference proceedings, etc)\n",
      "253 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Slack Communities (ods.ai, kagglenoobs, etc)\n",
      "254 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - None\n",
      "255 Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Other\n",
      "256 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Amazon Web Services (AWS) \n",
      "257 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Microsoft Azure \n",
      "258 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Google Cloud Platform (GCP) \n",
      "259 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  IBM Cloud / Red Hat \n",
      "260 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Oracle Cloud \n",
      "261 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  SAP Cloud \n",
      "262 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  VMware Cloud \n",
      "263 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Salesforce Cloud \n",
      "264 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Alibaba Cloud \n",
      "265 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice -  Tencent Cloud \n",
      "266 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice - None\n",
      "267 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years? - Selected Choice - Other\n",
      "268 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Amazon EC2 \n",
      "269 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  AWS Lambda \n",
      "270 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Amazon Elastic Container Service \n",
      "271 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Azure Cloud Services \n",
      "272 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Microsoft Azure Container Instances \n",
      "273 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Azure Functions \n",
      "274 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Google Cloud Compute Engine \n",
      "275 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Google Cloud Functions \n",
      "276 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Google Cloud Run \n",
      "277 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice -  Google Cloud App Engine \n",
      "278 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice - None\n",
      "279 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products? (Select all that apply) - Selected Choice - Other\n",
      "280 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Amazon SageMaker \n",
      "281 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Amazon Forecast \n",
      "282 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Amazon Rekognition \n",
      "283 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Azure Machine Learning Studio \n",
      "284 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Azure Cognitive Services \n",
      "285 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Google Cloud AI Platform / Google Cloud ML Engine\n",
      "286 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Google Cloud Video AI \n",
      "287 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Google Cloud Natural Language \n",
      "288 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice -  Google Cloud Vision AI \n",
      "289 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice - None\n",
      "290 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products? (Select all that apply) - Selected Choice - Other\n",
      "291 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - MySQL \n",
      "292 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - PostgresSQL \n",
      "293 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - SQLite \n",
      "294 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Oracle Database \n",
      "295 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - MongoDB \n",
      "296 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Snowflake \n",
      "297 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - IBM Db2 \n",
      "298 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Microsoft SQL Server \n",
      "299 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Microsoft Access \n",
      "300 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Microsoft Azure Data Lake Storage \n",
      "301 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Amazon Redshift \n",
      "302 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Amazon Athena \n",
      "303 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Amazon DynamoDB \n",
      "304 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Google Cloud BigQuery \n",
      "305 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Google Cloud SQL \n",
      "306 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Google Cloud Firestore \n",
      "307 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - None\n",
      "308 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Other\n",
      "309 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Microsoft Power BI\n",
      "310 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Amazon QuickSight\n",
      "311 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Google Data Studio\n",
      "312 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Looker\n",
      "313 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Tableau\n",
      "314 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Salesforce\n",
      "315 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Einstein Analytics\n",
      "316 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Qlik\n",
      "317 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Domo\n",
      "318 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - TIBCO Spotfire\n",
      "319 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Alteryx \n",
      "320 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Sisense \n",
      "321 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - SAP Analytics Cloud \n",
      "322 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - None\n",
      "323 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? (Select all that apply) - Selected Choice - Other\n",
      "324 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Automated data augmentation (e.g. imgaug, albumentations)\n",
      "325 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Automated feature engineering/selection (e.g. tpot, boruta_py)\n",
      "326 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Automated model selection (e.g. auto-sklearn, xcessiv)\n",
      "327 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Automated model architecture searches (e.g. darts, enas)\n",
      "328 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)\n",
      "329 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Automation of full ML pipelines (e.g. Google Cloud AutoML, H20 Driverless AI)\n",
      "330 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - None\n",
      "331 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Other\n",
      "332 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -  Google Cloud AutoML \n",
      "333 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -  H20 Driverless AI  \n",
      "334 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -  Databricks AutoML \n",
      "335 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -  DataRobot AutoML \n",
      "336 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -   Tpot \n",
      "337 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -   Auto-Keras \n",
      "338 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -   Auto-Sklearn \n",
      "339 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -   Auto_ml \n",
      "340 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -   Xcessiv \n",
      "341 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice -   MLbox \n",
      "342 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - None\n",
      "343 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?  (Select all that apply) - Selected Choice - Other\n",
      "344 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Neptune.ai \n",
      "345 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Weights & Biases \n",
      "346 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Comet.ml \n",
      "347 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Sacred + Omniboard \n",
      "348 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  TensorBoard \n",
      "349 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Guild.ai \n",
      "350 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Polyaxon \n",
      "351 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Trains \n",
      "352 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice -  Domino Model Monitor \n",
      "353 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice - None\n",
      "354 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? (Select all that apply) - Selected Choice - Other\n",
      "355 nan\n",
      "356 nan\n"
     ]
    }
   ],
   "source": [
    "for idx, line in enumerate(import_df.iloc[0].values.tolist()):\n",
    "    print(idx, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab78da2",
   "metadata": {},
   "source": [
    "Notes\n",
    "- For questions involving (Select all that apply), I will convert all the answers into 1's and NaN into 0, then I will take the sum of the 1's and find the sum. This will answer how many of the respondents have answerd none, once, or more.\n",
    "- Given that there are answers with \"None\", all columns like this will be dropped because if the respondant answered \"None\", then none of the other options would be marked 1, thus the sum would be 0\n",
    "- I will also be sure to isolate Q24_encoded and Q24_buckets.\n",
    "- I will drop the column on duration, since how a long a data scientist took to answer the question is not related to their pay\n",
    "- Columns involving age, gender, country, highest level of formal education, and years of coding experience will be converted into encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb450d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q24_buckets = import_df[['Q24_buckets']].copy()\n",
    "Q24_Encoded = import_df[['Q24_Encoded']].copy()\n",
    "\n",
    "Q24_buckets.drop(labels = [0], axis = 0, inplace = True)\n",
    "Q24_Encoded.drop(labels = [0], axis = 0, inplace = True)\n",
    "\n",
    "Q24_buckets = Q24_buckets.fillna(value = 0, inplace = False)\n",
    "Q24_Encoded = Q24_Encoded.fillna(value= 0, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81cd4fa0-4f56-422d-9af6-040d8f9e39d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  1., 11.,  7.,  3.,  9.,  0., 12.,  6., 14.,  4.,  2.,  8.,\n",
       "        5., 13.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q24_Encoded.Q24_Encoded.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53aa1f53-4612-4756-9bff-2b6f87a1a980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q24_Encoded\n",
       "0.0            4441\n",
       "1.0            1114\n",
       "2.0             714\n",
       "10.0            573\n",
       "4.0             552\n",
       "3.0             540\n",
       "5.0             510\n",
       "6.0             408\n",
       "7.0             394\n",
       "12.0            347\n",
       "11.0            315\n",
       "9.0             280\n",
       "8.0             273\n",
       "14.0            153\n",
       "13.0            115\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q24_Encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a3e67d-8f1d-416c-bc65-0ae9b42075a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'Q24_Encoded'}>]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q24_Encoded.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01047acd-b796-4891-90a5-5b3119cdcdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6630e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = import_df.drop(labels = ['Q24_Encoded', 'Q24_buckets', 'Time from Start to Finish (seconds)'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51dbaabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = import_df.fillna(value = 0, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5845e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_columns = []\n",
    "for idx, line in enumerate(import_df.iloc[0].values.tolist()):\n",
    "    if \"None\" in line:\n",
    "        all_columns = import_df.columns.tolist()\n",
    "        none_columns.append(all_columns[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d077a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = import_df.drop(labels = none_columns, axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13238eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7_Part_1</th>\n",
       "      <th>Q7_Part_2</th>\n",
       "      <th>Q7_Part_3</th>\n",
       "      <th>Q7_Part_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35_B_Part_1</th>\n",
       "      <th>Q35_B_Part_2</th>\n",
       "      <th>Q35_B_Part_3</th>\n",
       "      <th>Q35_B_Part_4</th>\n",
       "      <th>Q35_B_Part_5</th>\n",
       "      <th>Q35_B_Part_6</th>\n",
       "      <th>Q35_B_Part_7</th>\n",
       "      <th>Q35_B_Part_8</th>\n",
       "      <th>Q35_B_Part_9</th>\n",
       "      <th>Q35_B_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your age (# years)?</td>\n",
       "      <td>What is your gender? - Selected Choice</td>\n",
       "      <td>In which country do you currently reside?</td>\n",
       "      <td>What is the highest level of formal education ...</td>\n",
       "      <td>Select the title most similar to your current ...</td>\n",
       "      <td>For how many years have you been writing code ...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>What programming languages do you use on a reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "      <td>In the next 2 years, do you hope to become mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-34</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>10-20 years</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-34</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Q1                                      Q2  \\\n",
       "0  What is your age (# years)?  What is your gender? - Selected Choice   \n",
       "1                        30-34                                     Man   \n",
       "2                        35-39                                     Man   \n",
       "3                        30-34                                     Man   \n",
       "4                        35-39                                     Man   \n",
       "\n",
       "                                          Q3  \\\n",
       "0  In which country do you currently reside?   \n",
       "1                   United States of America   \n",
       "2                                  Argentina   \n",
       "3                   United States of America   \n",
       "4                                    Germany   \n",
       "\n",
       "                                                  Q4  \\\n",
       "0  What is the highest level of formal education ...   \n",
       "1                                    Master’s degree   \n",
       "2                                  Bachelor’s degree   \n",
       "3                                    Master’s degree   \n",
       "4                                    Doctoral degree   \n",
       "\n",
       "                                                  Q5  \\\n",
       "0  Select the title most similar to your current ...   \n",
       "1                                      Data Engineer   \n",
       "2                                  Software Engineer   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "\n",
       "                                                  Q6  \\\n",
       "0  For how many years have you been writing code ...   \n",
       "1                                         5-10 years   \n",
       "2                                        10-20 years   \n",
       "3                                         5-10 years   \n",
       "4                                         5-10 years   \n",
       "\n",
       "                                           Q7_Part_1  \\\n",
       "0  What programming languages do you use on a reg...   \n",
       "1                                             Python   \n",
       "2                                                  0   \n",
       "3                                             Python   \n",
       "4                                             Python   \n",
       "\n",
       "                                           Q7_Part_2  \\\n",
       "0  What programming languages do you use on a reg...   \n",
       "1                                                  R   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                           Q7_Part_3  \\\n",
       "0  What programming languages do you use on a reg...   \n",
       "1                                                SQL   \n",
       "2                                                  0   \n",
       "3                                                SQL   \n",
       "4                                                SQL   \n",
       "\n",
       "                                           Q7_Part_4  ...  \\\n",
       "0  What programming languages do you use on a reg...  ...   \n",
       "1                                                  0  ...   \n",
       "2                                                  0  ...   \n",
       "3                                                  0  ...   \n",
       "4                                                  0  ...   \n",
       "\n",
       "                                        Q35_B_Part_1  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_2  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_3  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_4  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_5  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_6  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_7  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_8  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                        Q35_B_Part_9  \\\n",
       "0  In the next 2 years, do you hope to become mor...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                         Q35_B_OTHER  \n",
       "0  In the next 2 years, do you hope to become mor...  \n",
       "1                                                  0  \n",
       "2                                                  0  \n",
       "3                                                  0  \n",
       "4                                                  0  \n",
       "\n",
       "[5 rows x 326 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e7780dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df.drop(labels = [0], axis = 0, inplace = True) #now removing the first row since those are just the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8296026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7_Part_1</th>\n",
       "      <th>Q7_Part_2</th>\n",
       "      <th>Q7_Part_3</th>\n",
       "      <th>Q7_Part_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35_B_Part_1</th>\n",
       "      <th>Q35_B_Part_2</th>\n",
       "      <th>Q35_B_Part_3</th>\n",
       "      <th>Q35_B_Part_4</th>\n",
       "      <th>Q35_B_Part_5</th>\n",
       "      <th>Q35_B_Part_6</th>\n",
       "      <th>Q35_B_Part_7</th>\n",
       "      <th>Q35_B_Part_8</th>\n",
       "      <th>Q35_B_Part_9</th>\n",
       "      <th>Q35_B_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-34</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>10-20 years</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-34</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Man</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1   Q2                        Q3                 Q4  \\\n",
       "1  30-34  Man  United States of America    Master’s degree   \n",
       "2  35-39  Man                 Argentina  Bachelor’s degree   \n",
       "3  30-34  Man  United States of America    Master’s degree   \n",
       "4  35-39  Man                   Germany    Doctoral degree   \n",
       "5  35-39  Man  United States of America    Doctoral degree   \n",
       "\n",
       "                   Q5           Q6 Q7_Part_1 Q7_Part_2 Q7_Part_3 Q7_Part_4  \\\n",
       "1       Data Engineer   5-10 years    Python         R       SQL         0   \n",
       "2   Software Engineer  10-20 years         0         0         0         0   \n",
       "3      Data Scientist   5-10 years    Python         0       SQL         0   \n",
       "4      Data Scientist   5-10 years    Python         0       SQL         0   \n",
       "5  Research Scientist    1-2 years         0         R         0         0   \n",
       "\n",
       "   ... Q35_B_Part_1 Q35_B_Part_2 Q35_B_Part_3 Q35_B_Part_4 Q35_B_Part_5  \\\n",
       "1  ...            0            0            0            0            0   \n",
       "2  ...            0            0            0            0            0   \n",
       "3  ...            0            0            0            0            0   \n",
       "4  ...            0            0            0            0            0   \n",
       "5  ...            0            0            0            0            0   \n",
       "\n",
       "  Q35_B_Part_6 Q35_B_Part_7 Q35_B_Part_8 Q35_B_Part_9 Q35_B_OTHER  \n",
       "1            0            0            0            0           0  \n",
       "2            0            0            0            0           0  \n",
       "3            0            0            0            0           0  \n",
       "4            0            0            0            0           0  \n",
       "5            0            0            0            0           0  \n",
       "\n",
       "[5 rows x 326 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c0f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_list = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6'] #This is to convert all the different answer such as age group, gender, and location into encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13db8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dict = {}\n",
    "\n",
    "for col in encoding_list:\n",
    "    encoding_values = []\n",
    "    unique_string_list = []\n",
    "    \n",
    "    for encoding, unique_string in enumerate(import_df[col].unique()):\n",
    "        encoding_values.append(encoding)\n",
    "        unique_string_list.append(unique_string)\n",
    "    \n",
    "    col_dict = {}\n",
    "    \n",
    "    for idx, item in enumerate(encoding_values):\n",
    "        col_dict[unique_string_list[idx]] = encoding_values[idx]\n",
    "        \n",
    "    encoding_dict[col] = col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54c05146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': {'30-34': 0,\n",
       "  '35-39': 1,\n",
       "  '22-24': 2,\n",
       "  '55-59': 3,\n",
       "  '50-54': 4,\n",
       "  '25-29': 5,\n",
       "  '18-21': 6,\n",
       "  '40-44': 7,\n",
       "  '60-69': 8,\n",
       "  '45-49': 9,\n",
       "  '70+': 10},\n",
       " 'Q2': {'Man': 0,\n",
       "  'Woman': 1,\n",
       "  'Nonbinary': 2,\n",
       "  'Prefer not to say': 3,\n",
       "  'Prefer to self-describe': 4},\n",
       " 'Q3': {'United States of America': 0,\n",
       "  'Argentina': 1,\n",
       "  'Germany': 2,\n",
       "  'Canada': 3,\n",
       "  'Switzerland': 4,\n",
       "  'India': 5,\n",
       "  'Russia': 6,\n",
       "  'South Africa': 7,\n",
       "  'Netherlands': 8,\n",
       "  'Pakistan': 9,\n",
       "  'Other': 10,\n",
       "  'Indonesia': 11,\n",
       "  'Belarus': 12,\n",
       "  'Ukraine': 13,\n",
       "  'Saudi Arabia': 14,\n",
       "  'Taiwan': 15,\n",
       "  'China': 16,\n",
       "  'Italy': 17,\n",
       "  'United Arab Emirates': 18,\n",
       "  'Colombia': 19,\n",
       "  'Viet Nam': 20,\n",
       "  'United Kingdom of Great Britain and Northern Ireland': 21,\n",
       "  'Egypt': 22,\n",
       "  'Brazil': 23,\n",
       "  'Mexico': 24,\n",
       "  'Poland': 25,\n",
       "  'Nigeria': 26,\n",
       "  'France': 27,\n",
       "  'Belgium': 28,\n",
       "  'Turkey': 29,\n",
       "  'Spain': 30,\n",
       "  'Iran, Islamic Republic of...': 31,\n",
       "  'Japan': 32,\n",
       "  'Tunisia': 33,\n",
       "  'Romania': 34,\n",
       "  'Republic of Korea': 35,\n",
       "  'Chile': 36,\n",
       "  'Ireland': 37,\n",
       "  'Sweden': 38,\n",
       "  'Greece': 39,\n",
       "  'Australia': 40,\n",
       "  'Malaysia': 41,\n",
       "  'Philippines': 42,\n",
       "  'Nepal': 43,\n",
       "  'Kenya': 44,\n",
       "  'South Korea': 45,\n",
       "  'Morocco': 46,\n",
       "  'Portugal': 47,\n",
       "  'Thailand': 48,\n",
       "  'Peru': 49,\n",
       "  'Bangladesh': 50,\n",
       "  'Israel': 51,\n",
       "  'Sri Lanka': 52,\n",
       "  'Singapore': 53,\n",
       "  'Ghana': 54},\n",
       " 'Q4': {'Master’s degree': 0,\n",
       "  'Bachelor’s degree': 1,\n",
       "  'Doctoral degree': 2,\n",
       "  'Some college/university study without earning a bachelor’s degree': 3,\n",
       "  'Professional degree': 4,\n",
       "  'I prefer not to answer': 5,\n",
       "  'No formal education past high school': 6},\n",
       " 'Q5': {'Data Engineer': 0,\n",
       "  'Software Engineer': 1,\n",
       "  'Data Scientist': 2,\n",
       "  'Research Scientist': 3,\n",
       "  'Other': 4,\n",
       "  'Statistician': 5,\n",
       "  'Product/Project Manager': 6,\n",
       "  'Data Analyst': 7,\n",
       "  'Machine Learning Engineer': 8,\n",
       "  'Business Analyst': 9,\n",
       "  'DBA/Database Engineer': 10},\n",
       " 'Q6': {'5-10 years': 0,\n",
       "  '10-20 years': 1,\n",
       "  '1-2 years': 2,\n",
       "  '< 1 years': 3,\n",
       "  '3-5 years': 4,\n",
       "  '20+ years': 5,\n",
       "  'I have never written code': 6}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d2b972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7_Part_1</th>\n",
       "      <th>Q7_Part_2</th>\n",
       "      <th>Q7_Part_3</th>\n",
       "      <th>Q7_Part_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35_B_Part_1</th>\n",
       "      <th>Q35_B_Part_2</th>\n",
       "      <th>Q35_B_Part_3</th>\n",
       "      <th>Q35_B_Part_4</th>\n",
       "      <th>Q35_B_Part_5</th>\n",
       "      <th>Q35_B_Part_6</th>\n",
       "      <th>Q35_B_Part_7</th>\n",
       "      <th>Q35_B_Part_8</th>\n",
       "      <th>Q35_B_Part_9</th>\n",
       "      <th>Q35_B_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6 Q7_Part_1 Q7_Part_2 Q7_Part_3 Q7_Part_4  ...  \\\n",
       "1   0   0   0   0   0   0    Python         R       SQL         0  ...   \n",
       "2   1   0   1   1   1   1         0         0         0         0  ...   \n",
       "3   0   0   0   0   2   0    Python         0       SQL         0  ...   \n",
       "4   1   0   2   2   2   0    Python         0       SQL         0  ...   \n",
       "5   1   0   0   2   3   2         0         R         0         0  ...   \n",
       "\n",
       "  Q35_B_Part_1 Q35_B_Part_2 Q35_B_Part_3 Q35_B_Part_4 Q35_B_Part_5  \\\n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "5            0            0            0            0            0   \n",
       "\n",
       "  Q35_B_Part_6 Q35_B_Part_7 Q35_B_Part_8 Q35_B_Part_9 Q35_B_OTHER  \n",
       "1            0            0            0            0           0  \n",
       "2            0            0            0            0           0  \n",
       "3            0            0            0            0           0  \n",
       "4            0            0            0            0           0  \n",
       "5            0            0            0            0           0  \n",
       "\n",
       "[5 rows x 326 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df = import_df.replace(encoding_dict)\n",
    "import_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b95e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will now separate the already encoded responses from the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c557aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_array = import_df[['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q5']].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "470a5cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  1,  1,  1,  1],\n",
       "       [ 0,  0,  0,  0,  2,  2],\n",
       "       ...,\n",
       "       [ 0,  0, 23,  0,  3,  3],\n",
       "       [ 2,  0,  5,  1,  1,  1],\n",
       "       [ 2,  0,  9,  0,  8,  8]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43493317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = import_df.drop(labels = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "619f6155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q7_Part_1</th>\n",
       "      <th>Q7_Part_2</th>\n",
       "      <th>Q7_Part_3</th>\n",
       "      <th>Q7_Part_4</th>\n",
       "      <th>Q7_Part_5</th>\n",
       "      <th>Q7_Part_6</th>\n",
       "      <th>Q7_Part_7</th>\n",
       "      <th>Q7_Part_8</th>\n",
       "      <th>Q7_Part_9</th>\n",
       "      <th>Q7_Part_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35_B_Part_1</th>\n",
       "      <th>Q35_B_Part_2</th>\n",
       "      <th>Q35_B_Part_3</th>\n",
       "      <th>Q35_B_Part_4</th>\n",
       "      <th>Q35_B_Part_5</th>\n",
       "      <th>Q35_B_Part_6</th>\n",
       "      <th>Q35_B_Part_7</th>\n",
       "      <th>Q35_B_Part_8</th>\n",
       "      <th>Q35_B_Part_9</th>\n",
       "      <th>Q35_B_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Java</td>\n",
       "      <td>Javascript</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bash</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bash</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bash</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C++</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TensorBoard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Trains</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>Java</td>\n",
       "      <td>Javascript</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Neptune.ai</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TensorBoard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Trains</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10729</th>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Trains</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10729 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q7_Part_1 Q7_Part_2 Q7_Part_3 Q7_Part_4 Q7_Part_5 Q7_Part_6   Q7_Part_7  \\\n",
       "1        Python         R       SQL         0         0         0           0   \n",
       "2             0         0         0         0         0      Java  Javascript   \n",
       "3        Python         0       SQL         0         0         0           0   \n",
       "4        Python         0       SQL         0         0         0           0   \n",
       "5             0         R         0         0         0         0           0   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "10725    Python         0         0         0       C++         0           0   \n",
       "10726         0         0       SQL         C         0         0           0   \n",
       "10727    Python         0         0         0         0         0           0   \n",
       "10728    Python         0       SQL         C         0      Java  Javascript   \n",
       "10729    Python         0         0         0         0         0           0   \n",
       "\n",
       "      Q7_Part_8 Q7_Part_9 Q7_Part_10  ...  Q35_B_Part_1        Q35_B_Part_2  \\\n",
       "1             0         0          0  ...             0                   0   \n",
       "2             0         0       Bash  ...             0                   0   \n",
       "3             0         0       Bash  ...             0                   0   \n",
       "4             0         0       Bash  ...             0                   0   \n",
       "5             0         0          0  ...             0                   0   \n",
       "...         ...       ...        ...  ...           ...                 ...   \n",
       "10725         0         0          0  ...             0                   0   \n",
       "10726         0         0          0  ...             0                   0   \n",
       "10727         0         0          0  ...             0                   0   \n",
       "10728         0         0          0  ...   Neptune.ai    Weights & Biases    \n",
       "10729         0         0          0  ...             0   Weights & Biases    \n",
       "\n",
       "      Q35_B_Part_3 Q35_B_Part_4   Q35_B_Part_5 Q35_B_Part_6 Q35_B_Part_7  \\\n",
       "1                0            0              0            0            0   \n",
       "2                0            0              0            0            0   \n",
       "3                0            0              0            0            0   \n",
       "4                0            0              0            0            0   \n",
       "5                0            0              0            0            0   \n",
       "...            ...          ...            ...          ...          ...   \n",
       "10725            0            0   TensorBoard             0            0   \n",
       "10726            0            0              0            0            0   \n",
       "10727            0            0              0            0            0   \n",
       "10728            0            0   TensorBoard             0            0   \n",
       "10729            0            0              0            0            0   \n",
       "\n",
       "      Q35_B_Part_8 Q35_B_Part_9 Q35_B_OTHER  \n",
       "1                0            0           0  \n",
       "2                0            0           0  \n",
       "3                0            0           0  \n",
       "4                0            0           0  \n",
       "5                0            0           0  \n",
       "...            ...          ...         ...  \n",
       "10725      Trains             0           0  \n",
       "10726            0            0           0  \n",
       "10727            0            0           0  \n",
       "10728      Trains             0           0  \n",
       "10729      Trains             0           0  \n",
       "\n",
       "[10729 rows x 320 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b78f4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(import_df) #Here comes the one-hot encoding and the summing of the respective question responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd069f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q7_Part_1_0</th>\n",
       "      <th>Q7_Part_1_Python</th>\n",
       "      <th>Q7_Part_2_0</th>\n",
       "      <th>Q7_Part_2_R</th>\n",
       "      <th>Q7_Part_3_0</th>\n",
       "      <th>Q7_Part_3_SQL</th>\n",
       "      <th>Q7_Part_4_0</th>\n",
       "      <th>Q7_Part_4_C</th>\n",
       "      <th>Q7_Part_5_0</th>\n",
       "      <th>Q7_Part_5_C++</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35_B_Part_6_0</th>\n",
       "      <th>Q35_B_Part_6_ Guild.ai</th>\n",
       "      <th>Q35_B_Part_7_0</th>\n",
       "      <th>Q35_B_Part_7_ Polyaxon</th>\n",
       "      <th>Q35_B_Part_8_0</th>\n",
       "      <th>Q35_B_Part_8_ Trains</th>\n",
       "      <th>Q35_B_Part_9_0</th>\n",
       "      <th>Q35_B_Part_9_ Domino Model Monitor</th>\n",
       "      <th>Q35_B_OTHER_0</th>\n",
       "      <th>Q35_B_OTHER_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q7_Part_1_0  Q7_Part_1_Python  Q7_Part_2_0  Q7_Part_2_R  Q7_Part_3_0  \\\n",
       "1            0                 1            0            1            0   \n",
       "2            1                 0            1            0            1   \n",
       "3            0                 1            1            0            0   \n",
       "4            0                 1            1            0            0   \n",
       "5            1                 0            0            1            1   \n",
       "\n",
       "   Q7_Part_3_SQL  Q7_Part_4_0  Q7_Part_4_C  Q7_Part_5_0  Q7_Part_5_C++  ...  \\\n",
       "1              1            1            0            1              0  ...   \n",
       "2              0            1            0            1              0  ...   \n",
       "3              1            1            0            1              0  ...   \n",
       "4              1            1            0            1              0  ...   \n",
       "5              0            1            0            1              0  ...   \n",
       "\n",
       "   Q35_B_Part_6_0  Q35_B_Part_6_ Guild.ai   Q35_B_Part_7_0  \\\n",
       "1               1                        0               1   \n",
       "2               1                        0               1   \n",
       "3               1                        0               1   \n",
       "4               1                        0               1   \n",
       "5               1                        0               1   \n",
       "\n",
       "   Q35_B_Part_7_ Polyaxon   Q35_B_Part_8_0  Q35_B_Part_8_ Trains   \\\n",
       "1                        0               1                      0   \n",
       "2                        0               1                      0   \n",
       "3                        0               1                      0   \n",
       "4                        0               1                      0   \n",
       "5                        0               1                      0   \n",
       "\n",
       "   Q35_B_Part_9_0  Q35_B_Part_9_ Domino Model Monitor   Q35_B_OTHER_0  \\\n",
       "1               1                                    0              1   \n",
       "2               1                                    0              1   \n",
       "3               1                                    0              1   \n",
       "4               1                                    0              1   \n",
       "5               1                                    0              1   \n",
       "\n",
       "   Q35_B_OTHER_Other  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "\n",
       "[5 rows x 742 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "233e9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all columns with \"_0\" in the encodings\n",
    "zeros_columns = []\n",
    "for column in dummy_df.columns.tolist():\n",
    "    if \"_0\" in column:\n",
    "        zeros_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3d0992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = dummy_df.drop(labels = zeros_columns, axis = 1, inplace = False) #this removes the one-hot encoding with 'zero' in the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60e5b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_numbers = ['Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71bc4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_encoded = np.zeros((len(dummy_df), len(question_numbers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cff978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_questions = []\n",
    "for question_idx, question in enumerate(question_numbers):\n",
    "    col_list = []\n",
    "    for col_name in dummy_df.columns.tolist():\n",
    "        if question in col_name:\n",
    "            col_list.append(col_name)\n",
    "    col_questions.append(col_list)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2aa72c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for question_idx, columns in enumerate(question_numbers):\n",
    "    question_df = dummy_df[col_questions[question_idx]].copy()\n",
    "    \n",
    "    for sample_idx in range(len(question_df)):\n",
    "        summed_encoded[sample_idx, question_idx] = question_df.iloc[sample_idx].sum()      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "373ecaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  1.,  3., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  1.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  2., ...,  0.,  0.,  0.],\n",
       "       [ 5.,  1.,  5., ...,  6., 10.,  4.],\n",
       "       [ 1.,  1.,  1., ...,  5.,  3.,  2.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "105aeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_array = np.concatenate((survey_array, summed_encoded), axis = 1) #combining the two arrays of data back into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52761811",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = pd.DataFrame(data = concat_array, columns = (['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6'] + question_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1e0357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10  ...  Q26  Q27  Q28  Q29  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  1.0  3.0  1.0  ...  3.0  4.0  1.0  3.0   \n",
       "1  1.0  0.0  1.0  1.0  1.0  1.0  3.0  1.0  4.0  0.0  ...  0.0  0.0  0.0  3.0   \n",
       "2  0.0  0.0  0.0  0.0  2.0  2.0  3.0  1.0  1.0  0.0  ...  2.0  2.0  0.0  2.0   \n",
       "3  1.0  0.0  2.0  2.0  2.0  2.0  3.0  1.0  4.0  2.0  ...  2.0  3.0  0.0  3.0   \n",
       "4  1.0  0.0  0.0  2.0  3.0  3.0  1.0  1.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   Q30  Q31  Q32  Q33  Q34  Q35  \n",
       "0  1.0  3.0  1.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  1.0  1.0  0.0  0.0  0.0  0.0  \n",
       "3  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "817d0cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1     0\n",
       "Q2     0\n",
       "Q3     0\n",
       "Q4     0\n",
       "Q5     0\n",
       "Q6     0\n",
       "Q7     0\n",
       "Q8     0\n",
       "Q9     0\n",
       "Q10    0\n",
       "Q11    0\n",
       "Q12    0\n",
       "Q13    0\n",
       "Q14    0\n",
       "Q15    0\n",
       "Q16    0\n",
       "Q17    0\n",
       "Q18    0\n",
       "Q19    0\n",
       "Q20    0\n",
       "Q21    0\n",
       "Q22    0\n",
       "Q23    0\n",
       "Q24    0\n",
       "Q25    0\n",
       "Q26    0\n",
       "Q27    0\n",
       "Q28    0\n",
       "Q29    0\n",
       "Q30    0\n",
       "Q31    0\n",
       "Q32    0\n",
       "Q33    0\n",
       "Q34    0\n",
       "Q35    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.isnull().sum(axis = 0) #checking if there are any NaN values missed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b541a3c",
   "metadata": {},
   "source": [
    "# Exploratory data analysis and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3be2642b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Q1', ylabel='count'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Q1', data = survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b22b684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, count = np.unique(survey_df['Q1'], return_counts = True)\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.barh(labels, count)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e71e1",
   "metadata": {},
   "source": [
    "Note: Mostly Under 1 year or 1-2 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec196d",
   "metadata": {},
   "source": [
    "Encodings\n",
    "{'Q1': {'30-34': 0,\n",
    "  '35-39': 1,\n",
    "  '22-24': 2,\n",
    "  '55-59': 3,\n",
    "  '50-54': 4,\n",
    "  '25-29': 5,\n",
    "  '18-21': 6,\n",
    "  '40-44': 7,\n",
    "  '60-69': 8,\n",
    "  '45-49': 9,\n",
    "  '70+': 10},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "037e1146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAFzCAYAAADSRaTQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXlklEQVR4nO3df7CnVX0f8PfHXdRFYDUFrAHraktMNCiYlZqSZpQai12rNjURZzQx2uAYk1Fj46wmncTpj9DROGkyJiNB/FGNxqCmKP7CKJAaq9xFdFWgMmaJgC061gXEAVk//eOeDdfN7t2v3H3u9+7e12vmO/d5zvP9Puezu2d233P2fM9T3R0AACC5z7wLAACAtUI4BgCAQTgGAIBBOAYAgEE4BgCAQTgGAIBh47wLWOr444/vLVu2zLsMAACOYDt27PhGd5+wv2trKhxv2bIlCwsL8y4DAIAjWFXdcKBrllUAAMAgHAMAwCAcAwDAIBwDAMAgHAMAwCAcAwDAIBwDAMAgHAMAwCAcAwDAIBwDAMAgHAMAwCAcAwDAsHHeBSy186bd2bL9kh/oM7vO2zZRNQAArDdmjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYJg0HFfVA6vqoqq6tqquqaqfnLI/AABYiY0T3/+/Jflwdz+rqu6b5OiJ+wMAgHttsnBcVccl+ekkz0+S7r4ryV1T9QcAACs15bKKRyT5epI3V9Vnq+qCqnrAhP0BAMCKTBmONyZ5XJI/7u7Tk3w7yfZ931RV51bVQlUt7Llj94TlAADA8qYMxzcmubG7Pz3OL8piWP4+3X1+d2/t7q0bjt48YTkAALC8ycJxd/+fJF+tqkeOpn+R5EtT9QcAACs19W4Vv5bkHWOniq8k+aWJ+wMAgHtt0nDc3Vcn2TplHwAAcKh4Qh4AAAzCMQAADMIxAAAMwjEAAAzCMQAADMIxAAAMwjEAAAzCMQAADMIxAAAMwjEAAAzCMQAADMIxAAAMG+ddwFKnnrQ5C+dtm3cZAACsU2aOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGBYUw8B2XnT7mzZfskhu98uDxQBAOAHYOYYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAACGjVPevKp2JbktyZ4kd3f31in7AwCAlZg0HA9P6u5vrEI/AACwIpZVAADAMHU47iQfraodVXXuxH0BAMCKTL2s4szuvrmqTkxyaVVd291XLH3DCM3nJsmG406YuBwAADiwSWeOu/vm8fOWJO9LcsZ+3nN+d2/t7q0bjt48ZTkAALCsycJxVT2gqo7de5zkKUm+MFV/AACwUlMuq3hwkvdV1d5+/rS7PzxhfwAAsCKThePu/kqSx051fwAAONRs5QYAAINwDAAAg3AMAACDcAwAAINwDAAAg3AMAACDcAwAAINwDAAAg3AMAACDcAwAAINwDAAAg3AMAADDxnkXsNSpJ23Ownnb5l0GAADrlJljAAAYhGMAABiEYwAAGIRjAAAYhGMAABiEYwAAGIRjAAAYhGMAABjW1ENAdt60O1u2XzLvMlbVLg89AQBYM8wcAwDAIBwDAMAgHAMAwCAcAwDAIBwDAMAgHAMAwCAcAwDAIBwDAMAgHAMAwCAcAwDAIBwDAMAgHAMAwCAcAwDAMHk4rqoNVfXZqvrA1H0BAMBKrMbM8UuTXLMK/QAAwIpMGo6r6uQk25JcMGU/AABwKEw9c/z7SV6Z5HsHekNVnVtVC1W1sOeO3ROXAwAABzZZOK6qpyW5pbt3LPe+7j6/u7d299YNR2+eqhwAADioKWeOz0zy9KraleRdSc6qqrdP2B8AAKzIZOG4u1/V3Sd395Yk5yT5eHc/d6r+AABgpexzDAAAw8bV6KS7L0ty2Wr0BQAA95aZYwAAGIRjAAAYDrisoqp2Jun9XUrS3f2YyaoCAIA5WG7N8dNWrQoAAFgDDhiOu/uGvcdV9bAkp3T3x6pq03KfAwCAw9VB1xxX1S8nuSjJG0fTyUn+YsKaAABgLmb5Qt5Lsvi0u1uTpLu/nOTEKYsCAIB5mCUc39ndd+09qaqN2f8X9QAA4LA2Szi+vKpenWRTVf1Mkj9P8v5pywIAgNU3SzjenuTrSXYmeVGSDyb5rSmLAgCAeZhl14lnJHlbd//J1MUAAMA8zTJz/PQk/7uq/ntVbRtrjgEA4IhT3Qf/bl1VHZXkqUmeneSnklza3f/uUBezdevWXlhYONS3BQCAv1NVO7p76/6uzTQL3N3fraoPZXGXik1ZXGpxyMMxAADM0ywPATm7qt6S5Pokz0pyQZKHTFwXAACsullmjp+f5F1JXtTdd05bDgAAzM9BZ467+5wkn03yz5OkqjZV1bFTFwYAAKttlmUVv5zkoiRvHE0nJ/mLCWsCAIC5mGUrt5ckOTPJrUnS3V9OcuKURQEAwDzMEo7v7O679p6MfY4Pvv8bAAAcZmb5Qt7lVfXqJJuq6meS/EqS909RzM6bdmfL9kumuPWq2nXetnmXAADAvTDLzPH2JF9PsjPJi5J8MMlvTVkUAADMw0Fnjrv7e0n+ZLwAAOCIdcBwXFU7s8za4u5+zCQVAQDAnCw3c/y0VasCAADWgAOG4+6+YTULAQCAeZvlC3kAALAuCMcAADAIxwAAMBx0K7eqOjPJ7yR52Hh/JenufsS0pQEAwOqa5Ql5b0ry8iQ7kuyZthwAAJifWcLx7u7+0OSVAADAnM0Sjj9RVa9N8t4kd+5t7O6rJqsKAADmYJZw/E/Hz61L2jrJWYe+HAAAmJ+DhuPuftK9uXFV3T/JFUnuN/q5qLt/+97cCwAAVsNBt3Krqs1V9fqqWhiv36uqzTPc+84kZ3X3Y5OcluTsqnrCCusFAIDJzLLP8YVJbkvy8+N1a5I3H+xDvej2cXrUePW9rBMAACY3y5rjf9zd/3bJ+Wuq6upZbl5VG7K4Bdw/SfKG7v70D14iAACsjllmjr9TVT+192Q8FOQ7s9y8u/d092lJTk5yRlX9+L7vqapz9y7Z2HPH7hnLBgCAQ2+WmeMXJ3nrWGdcSb6Z5Pk/SCfd/a2quizJ2Um+sM+185OcnyT3e8gpll0AADA3s+xWcXWSx1bVceP81lluXFUnJPnuCMabkjw5yX9dQa0AADCpA4bjqnpud7+9qn59n/YkSXe//iD3fkgWZ5w3ZHH5xru7+wMrrBcAACaz3MzxA8bPY/dz7aDLH7r780lOvzdFAQDAPBwwHHf3G8fhx7r7k0uvjS/lAQDAEWWW3Sr+cMY2AAA4rC235vgnk/yzJCfss+74uCQbpi4MAABW23Jrju+b5JjxnqXrjm9N8qwpiwIAgHlYbs3x5Ukur6q3dPcNq1gTAADMxSwPAbmjql6b5NFJ7r+3sbvPmqwqAACYg1m+kPeOJNcmeXiS1yTZleTKCWsCAIC5mCUc/4PuflMWn3Z3eXe/IMkTJq4LAABW3SzLKr47fn6tqrYluTnJydOVBAAA8zFLOP5PVbU5ySuyuL/xcUlePmlVAAAwBwcNx939gXG4O8mTpi0HAADm56BrjqvqrVX1wCXnD6qqCyetCgAA5mCWZRWP6e5v7T3p7v9XVadPUcypJ23Ownnbprg1AAAc1Cy7Vdynqh6096SqfiizhWoAADiszBJyfy/JX1fVReP855L85+lKAgCA+ZjlC3lvq6qFJGclqSQ/291fmrwyAABYZQcNx1X1j5LcnuTipW3d/bdTFgYAAKttlmUVlyTpcbwpi4+Rvi7Jo6cqCgAA5mGWZRWnLj2vqscledFkFQEAwJzMslvF9+nuq5I8foJaAABgrmZZc/zrS07vk+RxSb4+WUUAADAns6w5PnbJ8d1ZXIP8nimK2XnT7mzZfskUtwYOYpcH8ADATGuOX7MahQAAwLwdMBxX1ftzzy4Vf093P32SigAAYE6Wmzl+3fj5s0n+YZK3j/PnJNk1YU0AADAXBwzH3X15klTVf+zun15y6f1VdcXklQEAwCqbZSu3E6rqEXtPqurhSU6YriQAAJiPWXareHmSy6rqK+N8SzwEBACAI9Asu1V8uKpOSfKjo+na7r5z2rIAAGD1HXBZRVW9csnp07v7c+N1Z1X9l1WoDQAAVtVya47PWXL8qn2unT1BLQAAMFfLheM6wPH+zgEA4LC3XDjuAxzv7xwAAA57y30h77FVdWsWZ4k3jeOM8/tPXhkAAKyy5R4CsmE1CwEAgHmb5SEg90pVPbSqPlFV11TVF6vqpVP1BQAAh8IsDwG5t+5O8oruvqqqjk2yo6ou7e4vTdgnAADca5PNHHf317r7qnF8W5Jrkpw0VX8AALBSk4XjpapqS5LTk3x6P9fOraqFqlrYc8fu1SgHAAD2a/JwXFXHJHlPkpd19637Xu/u87t7a3dv3XD05qnLAQCAA5o0HFfVUVkMxu/o7vdO2RcAAKzUlLtVVJI3Jbmmu18/VT8AAHCoTDlzfGaS5yU5q6quHq9/NWF/AACwIpNt5dbd/zOLT9MDAIDDwqrsVgEAAIcD4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAAho3zLmCpU0/anIXzts27DAAA1ikzxwAAMAjHAAAwCMcAADAIxwAAMAjHAAAwCMcAADAIxwAAMKypfY533rQ7W7ZfMu8yAFiDdtkHH1gFZo4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGCYLBxX1YVVdUtVfWGqPgAA4FCacub4LUnOnvD+AABwSE0Wjrv7iiTfnOr+AABwqFlzDAAAw9zDcVWdW1ULVbWw547d8y4HAIB1bO7huLvP7+6t3b11w9Gb510OAADr2NzDMQAArBVTbuX2ziSfSvLIqrqxql44VV8AAHAobJzqxt39nKnuDQAAU7CsAgAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAAbhGAAABuEYAAAG4RgAAIaN8y5gqVNP2pyF87bNuwwAANYpM8cAADAIxwAAMAjHAAAwCMcAADAIxwAAMAjHAAAwCMcAADAIxwAAMKyph4DsvGl3tmy/ZN5lAAAwoV1r+KFvZo4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGCYNBxX1dlVdV1VXV9V26fsCwAAVmqycFxVG5K8IclTkzwqyXOq6lFT9QcAACs15czxGUmu7+6vdPddSd6V5BkT9gcAACsyZTg+KclXl5zfONoAAGBNmjIc137a+u+9qercqlqoqoU9d+yesBwAAFjelOH4xiQPXXJ+cpKb931Td5/f3Vu7e+uGozdPWA4AACxvynB8ZZJTqurhVXXfJOckuXjC/gAAYEU2TnXj7r67qn41yUeSbEhyYXd/car+AABgpSYLx0nS3R9M8sEp+wAAgEPFE/IAAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBgEI4BAGAQjgEAYBCOAQBg2DjvApY69aTNWThv27zLAABgnTJzDAAAg3AMAACDcAwAAINwDAAAg3AMAACDcAwAAINwDAAAg3AMAACDcAwAAINwDAAAg3AMAACDcAwAAINwDAAAg3AMAABDdfe8a/g7VXVbkuvmXQdzd3ySb8y7CNYEY4G9jAUS44B7rHQsPKy7T9jfhY0ruOkUruvurfMugvmqqgXjgMRY4B7GAolxwD2mHAuWVQAAwCAcAwDAsNbC8fnzLoA1wThgL2OBvYwFEuOAe0w2FtbUF/IAAGCe1trMMQAAzM2aCMdVdXZVXVdV11fV9nnXw6FXVRdW1S1V9YUlbT9UVZdW1ZfHzwctufaqMR6uq6p/uaT9J6pq57j2B1VVq/1r4d6rqodW1Seq6pqq+mJVvXS0GwvrTFXdv6o+U1WfG2PhNaPdWFiHqmpDVX22qj4wzo2Ddaiqdo0/w6uramG0rfpYmHs4rqoNSd6Q5KlJHpXkOVX1qPlWxQTekuTsfdq2J/nL7j4lyV+O84w//3OSPHp85o/GOEmSP05ybpJTxmvfe7K23Z3kFd39Y0mekOQl48/bWFh/7kxyVnc/NslpSc6uqifEWFivXprkmiXnxsH69aTuPm3JNm2rPhbmHo6TnJHk+u7+SnffleRdSZ4x55o4xLr7iiTf3Kf5GUneOo7fmuSZS9rf1d13dvffJLk+yRlV9ZAkx3X3p3pxsfzblnyGw0B3f627rxrHt2XxH8OTYiysO73o9nF61Hh1jIV1p6pOTrItyQVLmo0D9lr1sbAWwvFJSb665PzG0caR78Hd/bVkMTQlOXG0H2hMnDSO923nMFRVW5KcnuTTMRbWpfFf6VcnuSXJpd1tLKxPv5/klUm+t6TNOFifOslHq2pHVZ072lZ9LKyFJ+Ttbx2ILTTWtwONCWPlCFFVxyR5T5KXdfetyywHMxaOYN29J8lpVfXAJO+rqh9f5u3GwhGoqp6W5Jbu3lFVT5zlI/tpMw6OHGd2981VdWKSS6vq2mXeO9lYWAszxzcmeeiS85OT3DynWlhd/3f890fGz1tG+4HGxI3jeN92DiNVdVQWg/E7uvu9o9lYWMe6+1tJLsviukBjYX05M8nTq2pXFpdVnlVVb49xsC51983j5y1J3pfFpberPhbWQji+MskpVfXwqrpvFhdXXzznmlgdFyf5xXH8i0n+x5L2c6rqflX18Cwupv/M+O+U26rqCeObp7+w5DMcBsaf25uSXNPdr19yyVhYZ6rqhDFjnKralOTJSa6NsbCudPeruvvk7t6SxX//P97dz41xsO5U1QOq6ti9x0mekuQLmcNYmPuyiu6+u6p+NclHkmxIcmF3f3HOZXGIVdU7kzwxyfFVdWOS305yXpJ3V9ULk/xtkp9Lku7+YlW9O8mXsri7wUvGf78myYuzuPPFpiQfGi8OH2cmeV6SnWOtaZK8OsbCevSQJG8d3y6/T5J3d/cHqupTMRbwd8J69OAsLq9KFvPpn3b3h6vqyqzyWPCEPAAAGNbCsgoAAFgThGMAABiEYwAAGIRjAAAYhGMAABjmvpUbwJGsqvYk2bmk6ZndvWtO5QBwELZyA5hQVd3e3ccc4Fpl8e/h761yWQAcgGUVAKuoqrZU1TVV9UdJrkry0Kr6jaq6sqo+X1WvWfLe36yq66rqY1X1zqr696P9sqraOo6PH4/eTVVtqKrXLrnXi0b7E8dnLqqqa6vqHSOYp6oeX1V/XVWfq6rPVNWxVfVXVXXakjo+WVWPWa3fI4B5sqwCYFqbljwN8G+SvDzJI5P8Unf/SlU9JYuPPT0jSSW5uKp+Osm3s/g43dOz+Hf1VUl2HKSvFybZ3d2Pr6r7JflkVX10XDs9yaOT3Jzkk0nOrKrPJPmzJM/u7iur6rgk30lyQZLnJ3lZVf1Ikvt19+dX+PsAcFgQjgGm9Z3uPm3vSVVtSXJDd/+v0fSU8frsOD8mi2H52CTv6+47xucunqGvpyR5TFU9a5xvHve6K8lnuvvGca+rk2xJsjvJ17r7yiTp7lvH9T9P8h+q6jeSvCCLj2EFWBeEY4DV9+0lx5Xkd7v7jUvfUFUvS3KgL4XcnXuWxd1/n3v9Wnd/ZJ97PTHJnUua9mTx7//aXx/dfUdVXZrkGUl+PsnWZX81AEcQa44B5usjSV5QVcckSVWdVFUnJrkiyb+pqk1VdWySf73kM7uS/MQ4ftY+93pxVR017vUjVfWAZfq+NskPV9Xjx/uPraq9kyYXJPmDJFd29zdX9CsEOIyYOQaYo+7+aFX9WJJPje/I3Z7kud19VVX9WZKrk9yQ5K+WfOx1Sd5dVc9L8vEl7RdkcbnEVeMLd19P8sxl+r6rqp6d5A+ralMW1xs/Ocnt3b2jqm5N8uZD8gsFOEzYyg3gMFBVv5PF0Pq6Vervh5NcluRHbTUHrCeWVQDwfarqF5J8OslvCsbAemPmGAAABjPHAAAwCMcAADAIxwAAMAjHAAAwCMcAADAIxwAAMPx/Y6YynpyJIN4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, count = np.unique(survey_df['Q4'], return_counts = True)\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.barh(labels, count)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Education level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe4a2b",
   "metadata": {},
   "source": [
    "Encodings: 'Q4': {'Master’s degree': 0,\n",
    "  'Bachelor’s degree': 1,\n",
    "  'Doctoral degree': 2,\n",
    "  'Some college/university study without earning a bachelor’s degree': 3,\n",
    "  'Professional degree': 4,\n",
    "  'I prefer not to answer': 5,\n",
    "  'No formal education past high school': 6},\n",
    " 'Q5': {'Data Engineer': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b03a3b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, count = np.unique(survey_df['Q3'], return_counts = True)\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.barh(labels, count)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5cd6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostly from the US, India, and \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a354b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, count = np.unique(Q24_Encoded, return_counts = True)\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.barh(labels, count)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Salary Encoding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0aa757",
   "metadata": {},
   "source": [
    "Note: Based on this data alone, I expect the model to be biased in outputting label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dc152b7-80b7-4ca9-a937-93ae6e4a2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_df = survey_df.join(other = Q24_Encoded, on = 'Q35', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "640cf18a-d7ca-42df-94fb-a9b14cb24d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 36)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6faaafe4-d51f-4585-9b5a-b9c047fc998d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q24_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10  ...  Q27  Q28  Q29  Q30  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  1.0  3.0  1.0  ...  4.0  1.0  3.0  1.0   \n",
       "1  1.0  0.0  1.0  1.0  1.0  1.0  3.0  1.0  4.0  0.0  ...  0.0  0.0  3.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  2.0  2.0  3.0  1.0  1.0  0.0  ...  2.0  0.0  2.0  1.0   \n",
       "3  1.0  0.0  2.0  2.0  2.0  2.0  3.0  1.0  4.0  2.0  ...  3.0  0.0  3.0  1.0   \n",
       "4  1.0  0.0  0.0  2.0  3.0  3.0  1.0  1.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   Q31  Q32  Q33  Q34  Q35  Q24_Encoded  \n",
       "0  3.0  1.0  0.0  0.0  0.0          NaN  \n",
       "1  0.0  0.0  0.0  0.0  0.0          NaN  \n",
       "2  1.0  0.0  0.0  0.0  0.0          NaN  \n",
       "3  0.0  0.0  0.0  0.0  1.0         10.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0          NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c47089b-ed62-40be-9803-e0fdb41cfcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2779c182160>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x = 'Q3', y = 'Q24_Encoded', data = exploratory_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcd3fa0e-5a70-4140-b874-8930b2b495c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2779c6977f0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x = 'Q5', y = 'Q24_Encoded', data = exploratory_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03d4e468-ed25-4774-ba67-bca7a7495ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2779c6f1ac0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x = 'Q4', y = 'Q24_Encoded', data = exploratory_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b74714-f3f4-40e4-bcf9-3d67834f3014",
   "metadata": {},
   "source": [
    "Notes \n",
    "- No clear correlation to encoded salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a172c4-a445-4266-96c9-8a13ac7a9688",
   "metadata": {},
   "source": [
    "# Ordinal logistic regression - model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27af31a3-e775-4059-8992-f7ced762946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = survey_df.copy()\n",
    "y = Q24_Encoded.copy()\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(x, y, test_size = 0.2, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57c5b0b2-9249-4c25-9886-dfa642653cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 35)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ef749e9-0ee9-4d96-882a-28518e81c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_train_predictions = np.zeros((len(x), 14))\n",
    "\n",
    "cross_val = KFold(n_splits = 10, shuffle = True)\n",
    "cross_val.get_n_splits(train_features)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cumulative_accuracy = []\n",
    "cumulative_f1 = []\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42745c1c-4ac9-455d-9491-d362678035ce",
   "metadata": {},
   "source": [
    "Hyperparameters for logistic regression are as follows:\n",
    "- penalty (l1, l2, elasticnet, none) default = l2\n",
    "- dual (bool)\n",
    "- tol (Float) tolerance for stopping criteria\n",
    "- C (float) -> inverse regularization strength.\n",
    "- fit_intercept: bool (default = True)\n",
    "- Intercept_scaling: float (only when using sovler liblinear)\n",
    "- class_weight (weights association with classes as a dictionairy)\n",
    "- random_state\n",
    "- solver (newton-cg, sag, saga, lbfgs'\n",
    "- max_iter (int)\n",
    "- multi_class \n",
    "- verbose\n",
    "- warm_start\n",
    "- n_jobs\n",
    "- l1_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa56fa6-f9aa-449c-b861-f97eab0d6847",
   "metadata": {},
   "source": [
    "Chosen parameters\n",
    "- max_iter, due to errors showing total no of iterations reached\n",
    "- regularization strength C, due to a wide range of possible hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3594c1-382d-4ddb-aca3-032ebe87d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f68947f-c6df-4c0a-9a30-ced209eda6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_train_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d8e701f-584d-4fef-b0da-19312e81a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.6828621126642082\n",
      "accuracy stdev: 0.012851010490432182\n",
      "Bucket f1: 0.7486635667808689\n",
      "F1 stdev: 0.013551725774726379\n"
     ]
    }
   ],
   "source": [
    "# 0 vs 1-13\n",
    "\n",
    "#Re-label the encodings based on what condition we're finding \n",
    "ordinal_val0 = val_labels.copy()\n",
    "ordinal_val0 = ordinal_val0.values\n",
    "ordinal_val0 = np.where(ordinal_val0 < 1, 0, 1)\n",
    "\n",
    "ordinal_train0 = train_labels.copy()\n",
    "ordinal_train0 = ordinal_train0.values\n",
    "ordinal_train0 = np.where(ordinal_train0 < 1, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train0[train_idx], ordinal_train0[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    #assign the probabilities. With the ordinal method, the other probabilities will be subtracted (shown later)\n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][0] = predict_test_proba[idx][0]\n",
    "    \n",
    "    #Making predictions to track performance\n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    #performance metrics\n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2ff5886-50af-4e0f-aac2-3d81e168c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.6553622551294263\n",
      "accuracy stdev: 0.017101426476281684\n",
      "Bucket f1: 0.6405159844856055\n",
      "F1 stdev: 0.01829474405646536\n"
     ]
    }
   ],
   "source": [
    "# 0-1 vs 2-13\n",
    "ordinal_val1 = val_labels.copy()\n",
    "ordinal_val1 = ordinal_val1.values\n",
    "ordinal_val1 = np.where(ordinal_val1 < 2, 0, 1)\n",
    "\n",
    "ordinal_train1 = train_labels.copy()\n",
    "ordinal_train1 = ordinal_train1.values\n",
    "ordinal_train1 = np.where(ordinal_train1 < 2, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train1[train_idx], ordinal_train1[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][1] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][0]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2229e98a-1714-431c-a969-0ae3b834639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.6635158787661698\n",
      "accuracy stdev: 0.014581477223126941\n",
      "Bucket f1: 0.557372849947104\n",
      "F1 stdev: 0.0188805653766975\n"
     ]
    }
   ],
   "source": [
    "#0-2 vs 3-13\n",
    "ordinal_val2 = val_labels.copy()\n",
    "ordinal_val2 = ordinal_val2.values\n",
    "ordinal_val2 = np.where(ordinal_val2 < 3, 0, 1)\n",
    "\n",
    "ordinal_train2 = train_labels.copy()\n",
    "ordinal_train2 = ordinal_train2.values\n",
    "ordinal_train2 = np.where(ordinal_train2 < 3, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train2[train_idx], ordinal_train2[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][2] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99db285e-cfde-420d-a514-a97848706ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.6861238877536898\n",
      "accuracy stdev: 0.020405371723064634\n",
      "Bucket f1: 0.4833091160207919\n",
      "F1 stdev: 0.032872755586440476\n"
     ]
    }
   ],
   "source": [
    "#0-3 vs 4-13\n",
    "\n",
    "ordinal_val3 = val_labels.copy()\n",
    "ordinal_val3 = ordinal_val3.values\n",
    "ordinal_val3 = np.where(ordinal_val3 < 4, 0, 1)\n",
    "\n",
    "ordinal_train3 = train_labels.copy()\n",
    "ordinal_train3 = ordinal_train3.values\n",
    "ordinal_train3 = np.where(ordinal_train3 < 4, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train3[train_idx], ordinal_train3[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][3] = predict_test_proba[idx][0] -   ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f3e6363-54f0-4631-85fa-a21d20427e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.7248076719555183\n",
      "accuracy stdev: 0.012231720354782968\n",
      "Bucket f1: 0.4109131967802674\n",
      "F1 stdev: 0.025211598431619936\n"
     ]
    }
   ],
   "source": [
    "#0-4 vs 5-13\n",
    "\n",
    "ordinal_val4 = val_labels.copy()\n",
    "ordinal_val4 = ordinal_val4.values\n",
    "ordinal_val4 = np.where(ordinal_val4 < 5, 0, 1)\n",
    "\n",
    "ordinal_train4 = train_labels.copy()\n",
    "ordinal_train4 = ordinal_train4.values\n",
    "ordinal_train4 = np.where(ordinal_train4 < 5, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train4[train_idx], ordinal_train4[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][4] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][3] - ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7087d98-6f00-4f4e-a67f-ade36f1bc845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.7595275310642016\n",
      "accuracy stdev: 0.011175259801114126\n",
      "Bucket f1: 0.3406434984957826\n",
      "F1 stdev: 0.026008864801092373\n"
     ]
    }
   ],
   "source": [
    "#0-5 vs 6-13 \n",
    "\n",
    "ordinal_val5 = val_labels.copy()\n",
    "ordinal_val5 = ordinal_val5.values\n",
    "ordinal_val5 = np.where(ordinal_val5 < 6, 0, 1)\n",
    "\n",
    "ordinal_train5 = train_labels.copy()\n",
    "ordinal_train5 = ordinal_train5.values\n",
    "ordinal_train5 = np.where(ordinal_train5 < 6, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train5[train_idx], ordinal_train5[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][5] = predict_test_proba[idx][0] -ordinal_train_predictions[sample_idx][4]- ordinal_train_predictions[sample_idx][3] - ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "        #print(ordinal_train_predictions[sample_idx][5])\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b13a01f-dc38-4cae-867b-0d86c1fafde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.7931962682253718\n",
      "accuracy stdev: 0.015262917221348189\n",
      "Bucket f1: 0.30864234420350856\n",
      "F1 stdev: 0.04845411943686502\n"
     ]
    }
   ],
   "source": [
    "#0-6 vs 7-13 \n",
    "ordinal_val6 = val_labels.copy()\n",
    "ordinal_val6 = ordinal_val6.values\n",
    "ordinal_val6 = np.where(ordinal_val6 < 7, 0, 1)\n",
    "\n",
    "ordinal_train6 = train_labels.copy()\n",
    "ordinal_train6 = ordinal_train6.values\n",
    "ordinal_train6 = np.where(ordinal_train6 < 7, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train6[train_idx], ordinal_train6[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][6] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][4]- ordinal_train_predictions[sample_idx][3] - ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "        \n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7947252f-8a5e-4f99-b8de-69f0760807e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.9741353718070831\n",
      "accuracy stdev: 0.003950433334749065\n",
      "Bucket f1: 0.0\n",
      "F1 stdev: 0.0\n"
     ]
    }
   ],
   "source": [
    "#0-12 vs 13 \n",
    "ordinal_val13 = val_labels.copy()\n",
    "ordinal_val13 = ordinal_val13.values\n",
    "ordinal_val13 = np.where(ordinal_val13 < 13, 0, 1)\n",
    "\n",
    "ordinal_train13 = train_labels.copy()\n",
    "ordinal_train13 = ordinal_train13.values\n",
    "ordinal_train13 = np.where(ordinal_train13 < 13, 0, 1)\n",
    "\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train13[train_idx], ordinal_train13[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][13] = predict_test_proba[idx][1]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aeacc6eb-187b-49f5-bb97-f6fc2d9c87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.9578240540987921\n",
      "accuracy stdev: 0.017630468720182486\n",
      "Bucket f1: 0.0017241379310344823\n",
      "F1 stdev: 0.007710579232757895\n"
     ]
    }
   ],
   "source": [
    "#0-11 vs 12-13\n",
    "ordinal_val12 = val_labels.copy()\n",
    "ordinal_val12 = ordinal_val12.values\n",
    "ordinal_val12 = np.where(ordinal_val12 < 12, 0, 1)\n",
    "\n",
    "ordinal_train12 = train_labels.copy()\n",
    "ordinal_train12 = ordinal_train12.values\n",
    "ordinal_train12 = np.where(ordinal_train12 < 12, 0, 1)\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train12[train_idx], ordinal_train12[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][12] = predict_test_proba[idx][1] - ordinal_train_predictions[sample_idx][13]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c435b5ef-5838-4da1-8dc6-d78709b5c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.9426785993724294\n",
      "accuracy stdev: 0.02659079882000719\n",
      "Bucket f1: 0.01306572347460161\n",
      "F1 stdev: 0.025503501121634648\n"
     ]
    }
   ],
   "source": [
    "#0-10 vs 11-13\n",
    "ordinal_val11= val_labels.copy()\n",
    "ordinal_val11 = ordinal_val11.values\n",
    "ordinal_val11 = np.where(ordinal_val11 < 11, 0, 1)\n",
    "\n",
    "ordinal_train11 = train_labels.copy()\n",
    "ordinal_train11 = ordinal_train11.values\n",
    "ordinal_train11 = np.where(ordinal_train11 < 11, 0, 1)\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train11[train_idx], ordinal_train11[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][11] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][12]-ordinal_train_predictions[sample_idx][13]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82a94dfe-eb45-4983-9d0c-485852a95052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.9235127309632548\n",
      "accuracy stdev: 0.04075326764667846\n",
      "Bucket f1: 0.04252218657930959\n",
      "F1 stdev: 0.05795372210226623\n"
     ]
    }
   ],
   "source": [
    "#0-9 vs 10-13\n",
    "ordinal_val10= val_labels.copy()\n",
    "ordinal_val10 = ordinal_val10.values\n",
    "ordinal_val10 = np.where(ordinal_val10 < 10, 0, 1)\n",
    "\n",
    "ordinal_train10 = train_labels.copy()\n",
    "ordinal_train10 = ordinal_train10.values\n",
    "ordinal_train10 = np.where(ordinal_train10 < 10, 0, 1)\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train10[train_idx], ordinal_train10[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][10] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b22fcb96-7907-4bfc-804e-d5aedfec1792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.9074222479111885\n",
      "accuracy stdev: 0.04928785767278281\n",
      "Bucket f1: 0.0720758542580508\n",
      "F1 stdev: 0.08107963005989059\n"
     ]
    }
   ],
   "source": [
    "#0-8 vs 9-13\n",
    "\n",
    "ordinal_val9= val_labels.copy()\n",
    "ordinal_val9 = ordinal_val9.values\n",
    "ordinal_val9 = np.where(ordinal_val9 < 9, 0, 1)\n",
    "\n",
    "ordinal_train9 = train_labels.copy()\n",
    "ordinal_train9 = ordinal_train9.values\n",
    "ordinal_train9 = np.where(ordinal_train9 < 9, 0, 1)\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train9[train_idx], ordinal_train9[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][9] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][10]-ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64072ab8-da5b-458d-ab6b-164d359ac345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.8930063146011924\n",
      "accuracy stdev: 0.05579184320571418\n",
      "Bucket f1: 0.10092350973376307\n",
      "F1 stdev: 0.09999335211786833\n"
     ]
    }
   ],
   "source": [
    "#0-7 vs 8-13\n",
    "\n",
    "ordinal_val8= val_labels.copy()\n",
    "ordinal_val8 = ordinal_val8.values\n",
    "ordinal_val8 = np.where(ordinal_val8 < 8, 0, 1)\n",
    "\n",
    "ordinal_train8 = train_labels.copy()\n",
    "ordinal_train8 = ordinal_train8.values\n",
    "ordinal_train8 = np.where(ordinal_train8 < 8, 0, 1)\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train8[train_idx], ordinal_train8[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][8] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][9]-ordinal_train_predictions[sample_idx][10]-ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61e20aa0-72f1-475e-9ec5-d5d309562d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket accuracy: 0.8788308315665708\n",
      "accuracy stdev: 0.062419414164848204\n",
      "Bucket f1: 0.1305196832640855\n",
      "F1 stdev: 0.11817748735212984\n"
     ]
    }
   ],
   "source": [
    "#0-6 vs 7-13 (perspective of 7)\n",
    "\n",
    "ordinal_val7= val_labels.copy()\n",
    "ordinal_val7 = ordinal_val7.values\n",
    "ordinal_val7 = np.where(ordinal_val7 < 7, 0, 1)\n",
    "\n",
    "ordinal_train7 = train_labels.copy()\n",
    "ordinal_train7 = ordinal_train7.values\n",
    "ordinal_train7 = np.where(ordinal_train7 < 7, 0, 1)\n",
    "\n",
    "for train_idx, test_idx in cross_val.split(train_features):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "    y_train, y_test = ordinal_train7[train_idx], ordinal_train7[test_idx]\n",
    "    \n",
    "    #scaling needed due to encodings using the sum of different values \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    #print(model_params)\n",
    "    \n",
    "    predict_test_proba = model.predict_proba(x_test)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(test_idx):\n",
    "        ordinal_train_predictions[sample_idx][7] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][8]-ordinal_train_predictions[sample_idx][9]-ordinal_train_predictions[sample_idx][10]-ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "    \n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "    fold_f1 = f1_score(y_test, predict_test)\n",
    "    \n",
    "    bucket_accuracy.append(fold_accuracy)\n",
    "    bucket_f1.append(fold_f1)\n",
    "    cumulative_accuracy.append(fold_accuracy)\n",
    "    cumulative_f1.append(fold_f1)\n",
    "\n",
    "    \n",
    "print(\"Bucket accuracy: \" + str(statistics.mean(bucket_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(bucket_accuracy)))\n",
    "print(\"Bucket f1: \" + str(statistics.mean(bucket_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(bucket_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6474e77-8aaf-4000-9799-a358231cdeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25271908, 0.07087703, 0.07947534, ..., 0.03675435, 0.02311383,\n",
       "        0.01253384],\n",
       "       [0.13144336, 0.08419066, 0.05365157, ..., 0.03688686, 0.1717407 ,\n",
       "        0.08515812],\n",
       "       [0.12966448, 0.08029547, 0.04975649, ..., 0.00109275, 0.22378871,\n",
       "        0.13049002],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model outputs\n",
    "ordinal_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce3eb471-24c9-4d7f-939f-a0d53fb0238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25271908, 0.07087703, 0.07947534, 0.08989638, 0.06673618,\n",
       "       0.06204839, 0.14825658, 0.06880048, 0.0295967 , 0.02585959,\n",
       "       0.08860963, 0.03675435, 0.02311383, 0.01253384])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing one sample in particular to see all inputs\n",
    "ordinal_train_predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae6a3574-1e0b-4fdf-9c17-ed40ad351a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative accuracy: 0.7940865304660415\n",
      "accuracy stdev: 0.10210169085591361\n",
      "Cumulative f1 score: 0.31454988139732337\n",
      "F1 stdev: 0.22926867776929663\n"
     ]
    }
   ],
   "source": [
    "print(\"Cumulative accuracy: \" + str(statistics.mean(cumulative_accuracy)))\n",
    "print(\"accuracy stdev: \" + str(statistics.stdev(cumulative_accuracy)))\n",
    "print(\"Cumulative f1 score: \" + str(statistics.mean(cumulative_f1)))\n",
    "print(\"F1 stdev: \" + str(statistics.stdev(cumulative_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071e0f3-9c92-4757-891b-7daba85ff247",
   "metadata": {},
   "source": [
    "# Ordinal logisitc regression - model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9df901-b897-4978-95b6-f8196af33bcc",
   "metadata": {},
   "source": [
    "Hyperparameters for logistic regression are as follows:\n",
    "- penalty (l1, l2, elasticnet, none) default = l2\n",
    "- dual (bool)\n",
    "- tol (Float) tolerance for stopping criteria\n",
    "- C (float) -> inverse regularization strength.\n",
    "- fit_intercept: bool (default = True)\n",
    "- Intercept_scaling: float (only when using sovler liblinear)\n",
    "- class_weight (weights association with classes as a dictionairy)\n",
    "- random_state\n",
    "- solver (newton-cg, sag, saga, lbfgs'\n",
    "- max_iter (int)\n",
    "- multi_class \n",
    "- verbose\n",
    "- warm_start\n",
    "- n_jobs\n",
    "- l1_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be452acc-7f07-49c7-b170-7ffde7ff0e65",
   "metadata": {},
   "source": [
    "Chosen parameters\n",
    "- max_iter, due to errors showing total no of iterations reached\n",
    "- regularization strength C, due to a wide range of possible hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "801163c7-4a75-4dae-816c-5778ae0b637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_train_predictions = np.zeros((len(x), 14))\n",
    "\n",
    "cross_val = KFold(n_splits = 10, shuffle = True)\n",
    "cross_val.get_n_splits(train_features)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cumulative_accuracy = []\n",
    "cumulative_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0a64fd7-bb33-4e0b-80d1-ae307b27a1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 0.01, 'max_iter': 100}\n",
      "Bucket accuracy: 0.6844966636002725\n",
      "accuracy stdev: 0.014770073542659039\n",
      "Bucket f1: 0.7515002955689133\n",
      "F1 stdev: 0.01272674083016614\n"
     ]
    }
   ],
   "source": [
    "# 0 vs 1-13\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train0[train_idx], ordinal_train0[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][0] = predict_test_proba[idx][0]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e96b09f-b6e7-46ae-916f-78de05b363d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 1, 'max_iter': 200}\n",
      "Bucket accuracy: 0.6595560241078285\n",
      "accuracy stdev: 0.0193860574753703\n",
      "Bucket f1: 0.6450338074865984\n",
      "F1 stdev: 0.021528855271905404\n"
     ]
    }
   ],
   "source": [
    "# 0-1 vs 2-13\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train1[train_idx], ordinal_train1[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][1] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][0]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "225541b6-c5ce-4519-97df-c64bf60b5142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 10, 'max_iter': 200}\n",
      "Bucket accuracy: 0.666200330519306\n",
      "accuracy stdev: 0.019583552947345498\n",
      "Bucket f1: 0.5603574633714754\n",
      "F1 stdev: 0.02456809818701375\n"
     ]
    }
   ],
   "source": [
    "#0-2 vs 3-13\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train2[train_idx], ordinal_train2[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][2] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc1919bf-b629-4513-9976-5fee5950711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 1, 'max_iter': 300}\n",
      "Bucket accuracy: 0.6883432244899067\n",
      "accuracy stdev: 0.018300981312171744\n",
      "Bucket f1: 0.4876946492198603\n",
      "F1 stdev: 0.02592714474835774\n"
     ]
    }
   ],
   "source": [
    "#0-3 vs 4-13\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train3[train_idx], ordinal_train3[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][3] = predict_test_proba[idx][0] -   ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62b89599-df64-4257-b288-1d5d93dbd3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 1, 'max_iter': 300}\n",
      "Bucket accuracy: 0.726669081791317\n",
      "accuracy stdev: 0.013579809591126625\n",
      "Bucket f1: 0.41256494470720717\n",
      "F1 stdev: 0.03121732534707637\n"
     ]
    }
   ],
   "source": [
    "#0-4 vs 5-13\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train4[train_idx], ordinal_train4[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][4] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][3] - ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f797664e-921f-4244-9bf7-a700e191a02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 1, 'max_iter': 400}\n",
      "Bucket accuracy: 0.7623203920642803\n",
      "accuracy stdev: 0.012268908507091449\n",
      "Bucket f1: 0.3495334458460985\n",
      "F1 stdev: 0.02436913197035071\n"
     ]
    }
   ],
   "source": [
    "#0-5 vs 6-13 \n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train5[train_idx], ordinal_train5[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][5] = predict_test_proba[idx][0] -ordinal_train_predictions[sample_idx][4]- ordinal_train_predictions[sample_idx][3] - ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "            #print(ordinal_train_predictions[sample_idx][5])\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "467cddf4-189a-4a6b-922d-e6a1e577ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 10, 'max_iter': 200}\n",
      "Bucket accuracy: 0.7949408565823001\n",
      "accuracy stdev: 0.012004449706589726\n",
      "Bucket f1: 0.3160907554477337\n",
      "F1 stdev: 0.04568541295481581\n"
     ]
    }
   ],
   "source": [
    "#0-6 vs 7-13 \n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train6[train_idx], ordinal_train6[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][6] = predict_test_proba[idx][0] - ordinal_train_predictions[sample_idx][5]-ordinal_train_predictions[sample_idx][4]- ordinal_train_predictions[sample_idx][3] - ordinal_train_predictions[sample_idx][2]- ordinal_train_predictions[sample_idx][1] - ordinal_train_predictions[sample_idx][0]\n",
    "\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e79f4ecf-0451-49e1-90a9-95f5f9ccf638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: \n",
      "None\n",
      "Bucket accuracy: 0\n",
      "accuracy stdev: 0\n",
      "Bucket f1: 0\n",
      "F1 stdev: 0\n"
     ]
    }
   ],
   "source": [
    "#0-12 vs 13 \n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train13[train_idx], ordinal_train13[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][13] = predict_test_proba[idx][1]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6e7287a-ab6c-41a4-a618-f2b4d12e06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 1, 'max_iter': 300}\n",
      "Bucket accuracy: 0.866017160953133\n",
      "accuracy stdev: 0.014973115558597311\n",
      "Bucket f1: 0.13364303973890929\n",
      "F1 stdev: 0.028331090307834504\n"
     ]
    }
   ],
   "source": [
    "#0-11 vs 12-13\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train10[train_idx], ordinal_train10[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][12] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][13]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1d55a8b-5aa1-4039-bdd8-89f58ddb5567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 10, 'max_iter': 200}\n",
      "Bucket accuracy: 0.866127198373997\n",
      "accuracy stdev: 0.01552587024862185\n",
      "Bucket f1: 0.13703213158211355\n",
      "F1 stdev: 0.04434703931331456\n"
     ]
    }
   ],
   "source": [
    "#0-10 vs 11-13\n",
    "\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train10[train_idx], ordinal_train10[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][11] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8076152a-445d-4d8b-873b-b00f00893530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 0.1, 'max_iter': 300}\n",
      "Bucket accuracy: 0.8431791723991957\n",
      "accuracy stdev: 0.013703913138800936\n",
      "Bucket f1: 0.18943801282018377\n",
      "F1 stdev: 0.03496086320823703\n"
     ]
    }
   ],
   "source": [
    "#0-9 vs 10-13\n",
    "\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train9[train_idx], ordinal_train9[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][10] = predict_test_proba[idx][1] - ordinal_train_predictions[sample_idx][11] -ordinal_train_predictions[sample_idx][12]-ordinal_train_predictions[sample_idx][13]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "675eee13-0e7b-4f45-85f4-15b6603a8f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 1, 'max_iter': 200}\n",
      "Bucket accuracy: 0.8217395138815395\n",
      "accuracy stdev: 0.010530239175980857\n",
      "Bucket f1: 0.24898906241606072\n",
      "F1 stdev: 0.03685450324855888\n"
     ]
    }
   ],
   "source": [
    "#0-8 vs 9-13\n",
    "\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train8[train_idx], ordinal_train8[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][9] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][10]-ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df45610e-e57f-49bb-b0c7-7e9027d27710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 10, 'max_iter': 300}\n",
      "Bucket accuracy: 0.82267150777046\n",
      "accuracy stdev: 0.00842828653382135\n",
      "Bucket f1: 0.25248119629426347\n",
      "F1 stdev: 0.02706827878517116\n"
     ]
    }
   ],
   "source": [
    "#0-7 vs 8-13\n",
    "\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train8[train_idx], ordinal_train8[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][8] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][9]-ordinal_train_predictions[sample_idx][10]-ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aef81db9-23c3-4d15-8f2a-ea30d51e731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Found new parameter based on F1\n",
      "Best parameters: \n",
      "{'C': 10, 'max_iter': 200}\n",
      "Bucket accuracy: 0.7938970614174339\n",
      "accuracy stdev: 0.015903876317099774\n",
      "Bucket f1: 0.31301413032194125\n",
      "F1 stdev: 0.04778278129636672\n"
     ]
    }
   ],
   "source": [
    "#0-6 vs 7-13 (from label 7)\n",
    "\n",
    "parameter_grid = {'C': [0.01, 0.1, 1, 10], 'max_iter': [100, 200, 300, 400]}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_stdev = 0\n",
    "best_f1 = 0\n",
    "best_f1_stdev = 0\n",
    "best_grid = None \n",
    "\n",
    "\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    \n",
    "    bucket_accuracy = []\n",
    "    bucket_f1 = []\n",
    "    \n",
    "    for train_idx, test_idx in cross_val.split(train_features):\n",
    "        model = LogisticRegression()\n",
    "        model.set_params(**params)\n",
    "\n",
    "        x_train, x_test = train_features.values[train_idx], train_features.values[test_idx]\n",
    "        y_train, y_test = ordinal_train7[train_idx], ordinal_train7[test_idx]\n",
    "\n",
    "        #scaling needed due to encodings using the sum of different values \n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        model_params = model.get_params()\n",
    "        #print(model_params)\n",
    "\n",
    "        predict_test_proba = model.predict_proba(x_test)\n",
    "\n",
    "        for idx, sample_idx in enumerate(test_idx):\n",
    "            ordinal_train_predictions[sample_idx][7] = predict_test_proba[idx][1] -ordinal_train_predictions[sample_idx][8]-ordinal_train_predictions[sample_idx][9]-ordinal_train_predictions[sample_idx][10]-ordinal_train_predictions[sample_idx][11]-ordinal_train_predictions[sample_idx][12] -ordinal_train_predictions[sample_idx][13]\n",
    "\n",
    "        predict_test = model.predict(x_test)\n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test, predict_test)\n",
    "        fold_f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "        bucket_accuracy.append(fold_accuracy)\n",
    "        bucket_f1.append(fold_f1)\n",
    "\n",
    "    param_accuracy = statistics.mean(bucket_accuracy)\n",
    "    param_accuracy_stdev = statistics.stdev(bucket_accuracy)\n",
    "    param_f1 = (statistics.mean(bucket_f1))\n",
    "    param_f1_stdev = statistics.stdev(bucket_f1)\n",
    "\n",
    "    if param_f1 > best_f1:\n",
    "        best_f1 = param_f1\n",
    "        best_accuracy = param_accuracy\n",
    "        best_accuracy_stdev = param_accuracy_stdev\n",
    "        best_f1_stdev = param_f1_stdev\n",
    "        best_grid = params\n",
    "\n",
    "\n",
    "        print(\"Found new parameter based on F1\")\n",
    "\n",
    "print(\"Best parameters: \")\n",
    "print(best_grid)\n",
    "print(\"Bucket accuracy: \" + str(best_accuracy))\n",
    "print(\"accuracy stdev: \" + str(best_accuracy_stdev))\n",
    "print(\"Bucket f1: \" + str(best_f1))\n",
    "print(\"F1 stdev: \" + str(best_f1_stdev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cbe8e-f7f7-46b1-8ef5-8c35458ee57d",
   "metadata": {},
   "source": [
    "# Ordinal logistic regression - Testing & Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bcf434a6-6f7e-49a8-b522-947fb03d0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, train_labels, val_labels = train_test_split(x, y, test_size = 0.2, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6eb2ae88-0aab-45ca-be43-de28d5ca1268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  592,   608,   424, 10134,  5635,  5466,  9046,  5532,  8899,\n",
       "             7200,\n",
       "            ...\n",
       "             4317,   353,   456,  5298,   239,  5424,  2588,  8999,  4872,\n",
       "             8764],\n",
       "           dtype='int64', length=2146)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac48a529-e762-4882-820b-4107d8aa406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features.values\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "final_val_features = val_features.values\n",
    "final_val_features = scaler.fit_transform(final_val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8db1635-7fee-4bc4-a7f5-a3660bd44824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2968, 1018, 7366, 9575, 1760, 2391, 9427, 9578, 1103, 8819,\n",
       "            ...\n",
       "            8322, 5578, 4426,  466, 6265, 5734, 5191, 5390,  860, 7270],\n",
       "           dtype='int64', length=8583)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "91a2f2e0-59aa-41b0-af51-e7825b02402a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  592,   608,   424, 10134,  5635,  5466,  9046,  5532,  8899,\n",
       "             7200,\n",
       "            ...\n",
       "             4317,   353,   456,  5298,   239,  5424,  2588,  8999,  4872,\n",
       "             8764],\n",
       "           dtype='int64', length=2146)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb1ee236-8adf-46a8-ac3b-20a031e3e756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8583, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a249219-e69c-4b08-bd9b-08ef0c87d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = []\n",
    "val_f1 = []\n",
    "\n",
    "train_accuracy = []\n",
    "train_f1 = []\n",
    "\n",
    "final_ordinal_array = np.zeros((len(x), 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a1e23f75-6e71-4c18-8c9e-e95e897c00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 vs 1-13\n",
    "bucket_accuracy = []\n",
    "bucket_f1 = []\n",
    "\n",
    "ordinal_val0 = val_labels.copy()\n",
    "ordinal_val0 = ordinal_val0.values\n",
    "ordinal_val0 = np.where(ordinal_val0 < 1, 0, 1)\n",
    "\n",
    "ordinal_train0 = train_labels.copy()\n",
    "ordinal_train0 = ordinal_train0.values\n",
    "ordinal_train0 = np.where(ordinal_train0 < 1, 0, 1)\n",
    "    \n",
    "bucket0_final_model = LogisticRegression()\n",
    "bucket0_final_model.set_params(**{'C': 0.01, 'max_iter': 200})\n",
    "bucket0_final_model.fit(train_features, ordinal_train0)\n",
    "\n",
    "bucket0_train_predict = bucket0_final_model.predict(train_features)\n",
    "bucket0_train_proba = bucket0_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][0] = bucket0_train_proba[idx][0]\n",
    "bucket0_train_accuracy = accuracy_score(ordinal_train0, bucket0_train_predict)\n",
    "bucket0_train_f1 = f1_score(ordinal_train0, bucket0_train_predict)\n",
    "train_accuracy.append(bucket0_train_accuracy)\n",
    "train_f1.append(bucket0_train_f1)\n",
    "\n",
    "bucket0_val_predict = bucket0_final_model.predict(final_val_features)\n",
    "bucket0_val_proba = bucket0_final_model.predict_proba(final_val_features)\n",
    "bucket0_val_accuracy = accuracy_score(ordinal_val0, bucket0_val_predict)\n",
    "bucket0_val_f1 = f1_score(ordinal_val0, bucket0_val_predict)\n",
    "val_accuracy.append(bucket0_val_accuracy)\n",
    "val_f1.append(bucket0_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][0] = bucket0_val_proba[idx][0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e88c541-566c-4e14-aac9-3685fec47e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 vs 2-13\n",
    "ordinal_val1 = val_labels.copy()\n",
    "ordinal_val1 = ordinal_val1.values\n",
    "ordinal_val1 = np.where(ordinal_val1 < 2, 0, 1)\n",
    "\n",
    "ordinal_train1 = train_labels.copy()\n",
    "ordinal_train1 = ordinal_train1.values\n",
    "ordinal_train1 = np.where(ordinal_train1 < 2, 0, 1)\n",
    "\n",
    "bucket1_final_model = LogisticRegression()\n",
    "bucket1_final_model.set_params(**{'C': 1, 'max_iter': 400})\n",
    "bucket1_final_model.fit(train_features, ordinal_train1)\n",
    "\n",
    "bucket1_train_predict = bucket1_final_model.predict(train_features)\n",
    "bucket1_train_proba = bucket1_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][1] = bucket1_train_proba[idx][0] - final_ordinal_array[sample_idx][0]\n",
    "bucket1_train_accuracy = accuracy_score(ordinal_train1, bucket1_train_predict)\n",
    "bucket1_train_f1 = f1_score(ordinal_train1, bucket1_train_predict)\n",
    "train_accuracy.append(bucket1_train_accuracy)\n",
    "train_f1.append(bucket1_train_f1)\n",
    "\n",
    "bucket1_val_predict = bucket1_final_model.predict(final_val_features)\n",
    "bucket1_val_proba = bucket1_final_model.predict_proba(final_val_features)\n",
    "bucket1_val_accuracy = accuracy_score(ordinal_val1, bucket1_val_predict)\n",
    "bucket1_val_f1 = f1_score(ordinal_val1, bucket1_val_predict)\n",
    "val_accuracy.append(bucket1_val_accuracy)\n",
    "val_f1.append(bucket1_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][1] = bucket1_val_proba[idx][0] - final_ordinal_array[sample_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "572bffb7-4675-4e97-8a3e-916d1e3bb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-2 vs 3-13\n",
    "ordinal_val2 = val_labels.copy()\n",
    "ordinal_val2 = ordinal_val2.values\n",
    "ordinal_val2 = np.where(ordinal_val2 < 3, 0, 1)\n",
    "\n",
    "ordinal_train2 = train_labels.copy()\n",
    "ordinal_train2 = ordinal_train2.values\n",
    "ordinal_train2 = np.where(ordinal_train2 < 3, 0, 1)\n",
    "\n",
    "bucket2_final_model = LogisticRegression()\n",
    "bucket2_final_model.set_params(**{'C': 10, 'max_iter': 100})\n",
    "bucket2_final_model.fit(train_features, ordinal_train2)\n",
    "\n",
    "bucket2_train_predict = bucket2_final_model.predict(train_features)\n",
    "bucket2_train_proba = bucket2_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][2] = bucket2_train_proba[idx][0] -final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]\n",
    "bucket2_train_accuracy = accuracy_score(ordinal_train2, bucket2_train_predict)\n",
    "bucket2_train_f1 = f1_score(ordinal_train2, bucket2_train_predict)\n",
    "train_accuracy.append(bucket2_train_accuracy)\n",
    "train_f1.append(bucket2_train_f1)\n",
    "\n",
    "bucket2_val_predict = bucket2_final_model.predict(final_val_features)\n",
    "bucket2_val_proba = bucket2_final_model.predict_proba(final_val_features)\n",
    "bucket2_val_accuracy = accuracy_score(ordinal_val2, bucket2_val_predict)\n",
    "bucket2_val_f1 = f1_score(ordinal_val2, bucket2_val_predict)\n",
    "val_accuracy.append(bucket2_val_accuracy)\n",
    "val_f1.append(bucket2_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][2] = bucket2_val_proba[idx][0] -final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b53c1ccf-2292-409e-93ac-4418ada6c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-3 vs 4-13\n",
    "ordinal_val3 = val_labels.copy()\n",
    "ordinal_val3 = ordinal_val3.values\n",
    "ordinal_val3 = np.where(ordinal_val3 < 4, 0, 1)\n",
    "\n",
    "ordinal_train3 = train_labels.copy()\n",
    "ordinal_train3 = ordinal_train3.values\n",
    "ordinal_train3 = np.where(ordinal_train3 < 4, 0, 1)\n",
    "\n",
    "bucket3_final_model = LogisticRegression()\n",
    "bucket3_final_model.set_params(**{'C': 10, 'max_iter': 200})\n",
    "bucket3_final_model.fit(train_features, ordinal_train3)\n",
    "\n",
    "bucket3_train_predict = bucket3_final_model.predict(train_features)\n",
    "bucket3_train_proba = bucket3_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][3] = bucket3_train_proba[idx][0] -final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]\n",
    "bucket3_train_accuracy = accuracy_score(ordinal_train3, bucket3_train_predict)\n",
    "bucket3_train_f1 = f1_score(ordinal_train3, bucket3_train_predict)\n",
    "train_accuracy.append(bucket3_train_accuracy)\n",
    "train_f1.append(bucket3_train_f1)\n",
    "\n",
    "bucket3_val_predict = bucket3_final_model.predict(final_val_features)\n",
    "bucket3_val_proba = bucket3_final_model.predict_proba(final_val_features)\n",
    "bucket3_val_accuracy = accuracy_score(ordinal_val3, bucket3_val_predict)\n",
    "bucket3_val_f1 = f1_score(ordinal_val3, bucket3_val_predict)\n",
    "val_accuracy.append(bucket3_val_accuracy)\n",
    "val_f1.append(bucket3_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][3] = bucket3_val_proba[idx][0] -final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74e00489-910a-4c3c-a01d-c8c5d32a96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-4 vs 5-13\n",
    "\n",
    "ordinal_val4 = val_labels.copy()\n",
    "ordinal_val4 = ordinal_val4.values\n",
    "ordinal_val4 = np.where(ordinal_val4 < 5, 0, 1)\n",
    "\n",
    "ordinal_train4 = train_labels.copy()\n",
    "ordinal_train4 = ordinal_train4.values\n",
    "ordinal_train4 = np.where(ordinal_train4 < 5, 0, 1)\n",
    "\n",
    "bucket4_final_model = LogisticRegression()\n",
    "bucket4_final_model.set_params(**{'C': 10, 'max_iter': 400})\n",
    "bucket4_final_model.fit(train_features, ordinal_train4)\n",
    "\n",
    "bucket4_train_predict = bucket4_final_model.predict(train_features)\n",
    "bucket4_train_proba = bucket4_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][4] = bucket4_train_proba[idx][0] -final_ordinal_array[sample_idx][3]-final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]\n",
    "bucket4_train_accuracy = accuracy_score(ordinal_train4, bucket4_train_predict)\n",
    "bucket4_train_f1 = f1_score(ordinal_train4, bucket4_train_predict)\n",
    "train_accuracy.append(bucket4_train_accuracy)\n",
    "train_f1.append(bucket4_train_f1)\n",
    "\n",
    "bucket4_val_predict = bucket4_final_model.predict(final_val_features)\n",
    "bucket4_val_proba = bucket4_final_model.predict_proba(final_val_features)\n",
    "bucket4_val_accuracy = accuracy_score(ordinal_val4, bucket4_val_predict)\n",
    "bucket4_val_f1 = f1_score(ordinal_val4, bucket4_val_predict)\n",
    "val_accuracy.append(bucket4_val_accuracy)\n",
    "val_f1.append(bucket4_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][4] = bucket4_val_proba[idx][0] -final_ordinal_array[sample_idx][3]-final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b5a6968-ee0b-4334-9764-ba78feb217e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-5 vs 6-13 \n",
    "\n",
    "ordinal_val5 = val_labels.copy()\n",
    "ordinal_val5 = ordinal_val5.values\n",
    "ordinal_val5 = np.where(ordinal_val5 < 6, 0, 1)\n",
    "\n",
    "ordinal_train5 = train_labels.copy()\n",
    "ordinal_train5 = ordinal_train5.values\n",
    "ordinal_train5 = np.where(ordinal_train5 < 6, 0, 1)\n",
    "\n",
    "\n",
    "bucket5_final_model = LogisticRegression()\n",
    "bucket5_final_model.set_params(**{'C': 10, 'max_iter': 200})\n",
    "bucket5_final_model.fit(train_features, ordinal_train5)\n",
    "\n",
    "bucket5_train_predict = bucket5_final_model.predict(train_features)\n",
    "bucket5_train_proba = bucket5_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][5] = bucket5_train_proba[idx][0] -final_ordinal_array[sample_idx][4]-final_ordinal_array[sample_idx][3]-final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]\n",
    "bucket5_train_accuracy = accuracy_score(ordinal_train5, bucket5_train_predict)\n",
    "bucket5_train_f1 = f1_score(ordinal_train5, bucket5_train_predict)\n",
    "train_accuracy.append(bucket5_train_accuracy)\n",
    "train_f1.append(bucket5_train_f1)\n",
    "\n",
    "bucket5_val_predict = bucket5_final_model.predict(final_val_features)\n",
    "bucket5_val_proba = bucket5_final_model.predict_proba(final_val_features)\n",
    "bucket5_val_accuracy = accuracy_score(ordinal_val5, bucket5_val_predict)\n",
    "bucket5_val_f1 = f1_score(ordinal_val5, bucket5_val_predict)\n",
    "val_accuracy.append(bucket5_val_accuracy)\n",
    "val_f1.append(bucket5_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][5] = bucket5_val_proba[idx][0] -final_ordinal_array[sample_idx][4]-final_ordinal_array[sample_idx][3]-final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62b3202a-1da7-4167-85c5-8888d394d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-6 vs 7-13 \n",
    "\n",
    "ordinal_val6 = val_labels.copy()\n",
    "ordinal_val6 = ordinal_val6.values\n",
    "ordinal_val6 = np.where(ordinal_val6 < 7, 0, 1)\n",
    "\n",
    "ordinal_train6 = train_labels.copy()\n",
    "ordinal_train6 = ordinal_train6.values\n",
    "ordinal_train6 = np.where(ordinal_train6 < 7, 0, 1)\n",
    "\n",
    "bucket6_final_model = LogisticRegression()\n",
    "bucket6_final_model.set_params(**{'C': 1, 'max_iter': 100})\n",
    "bucket6_final_model.fit(train_features, ordinal_train6)\n",
    "\n",
    "bucket6_train_predict = bucket6_final_model.predict(train_features)\n",
    "bucket6_train_proba = bucket6_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][6] = bucket6_train_proba[idx][0] -final_ordinal_array[sample_idx][5]-final_ordinal_array[sample_idx][4]-final_ordinal_array[sample_idx][3]-final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]\n",
    "bucket6_train_accuracy = accuracy_score(ordinal_train6, bucket6_train_predict)\n",
    "bucket6_train_f1 = f1_score(ordinal_train6, bucket6_train_predict)\n",
    "train_accuracy.append(bucket6_train_accuracy)\n",
    "train_f1.append(bucket6_train_f1)\n",
    "\n",
    "bucket6_val_predict = bucket6_final_model.predict(final_val_features)\n",
    "bucket6_val_proba = bucket6_final_model.predict_proba(final_val_features)\n",
    "bucket6_val_accuracy = accuracy_score(ordinal_val6, bucket6_val_predict)\n",
    "bucket6_val_f1 = f1_score(ordinal_val6, bucket6_val_predict)\n",
    "val_accuracy.append(bucket6_val_accuracy)\n",
    "val_f1.append(bucket6_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][6] = bucket6_val_proba[idx][0]-final_ordinal_array[sample_idx][5] -final_ordinal_array[sample_idx][4]-final_ordinal_array[sample_idx][3]-final_ordinal_array[sample_idx][2]-final_ordinal_array[sample_idx][1] - final_ordinal_array[sample_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "901bfa92-2b27-4444-a933-a5a57acef31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-12 vs 13 \n",
    "\n",
    "ordinal_val13 = val_labels.copy()\n",
    "ordinal_val13 = ordinal_val13.values\n",
    "ordinal_val13 = np.where(ordinal_val12 < 13, 0, 1)\n",
    "\n",
    "ordinal_train13 = train_labels.copy()\n",
    "ordinal_train13 = ordinal_train13.values\n",
    "ordinal_train13 = np.where(ordinal_train13 < 13, 0, 1)\n",
    "\n",
    "bucket13_final_model = LogisticRegression()\n",
    "bucket13_final_model.fit(train_features, ordinal_train13)\n",
    "\n",
    "bucket13_train_predict = bucket13_final_model.predict(train_features)\n",
    "bucket13_train_proba = bucket13_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][13] = bucket13_train_proba[idx][1] \n",
    "bucket13_train_accuracy = accuracy_score(ordinal_train13, bucket13_train_predict)\n",
    "bucket13_train_f1 = f1_score(ordinal_train13, bucket13_train_predict)\n",
    "train_accuracy.append(bucket13_train_accuracy)\n",
    "train_f1.append(bucket13_train_f1)\n",
    "\n",
    "bucket13_val_predict = bucket13_final_model.predict(final_val_features)\n",
    "bucket13_val_proba = bucket13_final_model.predict_proba(final_val_features)\n",
    "bucket13_val_accuracy = accuracy_score(ordinal_val13, bucket13_val_predict)\n",
    "bucket13_val_f1 = f1_score(ordinal_val13, bucket13_val_predict)\n",
    "val_accuracy.append(bucket13_val_accuracy)\n",
    "val_f1.append(bucket13_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][13] = bucket13_val_proba[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84466d8d-842e-4d42-a335-d62f8759d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-11 vs 12-13\n",
    "ordinal_val12 = val_labels.copy()\n",
    "ordinal_val12 = ordinal_val12.values\n",
    "ordinal_val12 = np.where(ordinal_val12 < 12, 0, 1)\n",
    "\n",
    "ordinal_train12 = train_labels.copy()\n",
    "ordinal_train12 = ordinal_train12.values\n",
    "ordinal_train12 = np.where(ordinal_train12 < 12, 0, 1)\n",
    "\n",
    "bucket12_final_model = LogisticRegression()\n",
    "bucket12_final_model.set_params(**{'C': 10, 'max_iter': 100})\n",
    "bucket12_final_model.fit(train_features, ordinal_train12)\n",
    "\n",
    "bucket12_train_predict = bucket12_final_model.predict(train_features)\n",
    "bucket12_train_proba = bucket12_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][12] = bucket12_train_proba[idx][1] - final_ordinal_array[sample_idx][13]\n",
    "bucket12_train_accuracy = accuracy_score(ordinal_train12, bucket12_train_predict)\n",
    "bucket12_train_f1 = f1_score(ordinal_train12, bucket12_train_predict)\n",
    "train_accuracy.append(bucket12_train_accuracy)\n",
    "train_f1.append(bucket12_train_f1)\n",
    "\n",
    "bucket12_val_predict = bucket12_final_model.predict(final_val_features)\n",
    "bucket12_val_proba = bucket12_final_model.predict_proba(final_val_features)\n",
    "bucket12_val_accuracy = accuracy_score(ordinal_val12, bucket12_val_predict)\n",
    "bucket12_val_f1 = f1_score(ordinal_val12, bucket12_val_predict)\n",
    "val_accuracy.append(bucket12_val_accuracy)\n",
    "val_f1.append(bucket12_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][12] = bucket12_val_proba[idx][1] - final_ordinal_array[sample_idx][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "327e7104-b8a8-44e2-a038-3ac77c46045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-10 vs 11-13\n",
    "ordinal_val11= val_labels.copy()\n",
    "ordinal_val11 = ordinal_val11.values\n",
    "ordinal_val11 = np.where(ordinal_val11 < 11, 0, 1)\n",
    "\n",
    "ordinal_train11 = train_labels.copy()\n",
    "ordinal_train11 = ordinal_train11.values\n",
    "ordinal_train11 = np.where(ordinal_train11 < 11, 0, 1)\n",
    "\n",
    "bucket11_final_model = LogisticRegression()\n",
    "bucket11_final_model.set_params(**{'C': 1, 'max_iter': 200})\n",
    "bucket11_final_model.fit(train_features, ordinal_train11)\n",
    "\n",
    "bucket11_train_predict = bucket11_final_model.predict(train_features)\n",
    "bucket11_train_proba = bucket11_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][11] = bucket11_train_proba[idx][1] - final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]\n",
    "bucket11_train_accuracy = accuracy_score(ordinal_train11, bucket11_train_predict)\n",
    "bucket11_train_f1 = f1_score(ordinal_train11, bucket11_train_predict)\n",
    "train_accuracy.append(bucket11_train_accuracy)\n",
    "train_f1.append(bucket11_train_f1)\n",
    "\n",
    "bucket11_val_predict = bucket11_final_model.predict(final_val_features)\n",
    "bucket11_val_proba = bucket11_final_model.predict_proba(final_val_features)\n",
    "bucket11_val_accuracy = accuracy_score(ordinal_val11, bucket11_val_predict)\n",
    "bucket11_val_f1 = f1_score(ordinal_val11, bucket11_val_predict)\n",
    "val_accuracy.append(bucket11_val_accuracy)\n",
    "val_f1.append(bucket11_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][11] = bucket11_val_proba[idx][1] - final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "053ec65f-0c91-4283-886d-a6378129092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-9 vs 10-13\n",
    "ordinal_val10= val_labels.copy()\n",
    "ordinal_val10 = ordinal_val10.values\n",
    "ordinal_val10 = np.where(ordinal_val9 < 10, 0, 1)\n",
    "\n",
    "ordinal_train10 = train_labels.copy()\n",
    "ordinal_train10 = ordinal_train10.values\n",
    "ordinal_train10 = np.where(ordinal_train9 < 10, 0, 1)\n",
    "\n",
    "bucket10_final_model = LogisticRegression()\n",
    "bucket10_final_model.set_params(**{'C': 10, 'max_iter': 200})\n",
    "bucket10_final_model.fit(train_features, ordinal_train9)\n",
    "\n",
    "bucket10_train_predict = bucket10_final_model.predict(train_features)\n",
    "bucket10_train_proba = bucket10_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][10] = bucket10_train_proba[idx][1] - final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]\n",
    "bucket10_train_accuracy = accuracy_score(ordinal_train10, bucket10_train_predict)\n",
    "bucket10_train_f1 = f1_score(ordinal_train10, bucket10_train_predict)\n",
    "train_accuracy.append(bucket10_train_accuracy)\n",
    "train_f1.append(bucket10_train_f1)\n",
    "\n",
    "bucket10_val_predict = bucket10_final_model.predict(final_val_features)\n",
    "bucket10_val_proba = bucket10_final_model.predict_proba(final_val_features)\n",
    "bucket10_val_accuracy = accuracy_score(ordinal_val10, bucket10_val_predict)\n",
    "bucket10_val_f1 = f1_score(ordinal_val10, bucket10_val_predict)\n",
    "val_accuracy.append(bucket10_val_accuracy)\n",
    "val_f1.append(bucket10_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][10] = bucket10_val_proba[idx][1] - final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b13c0e4-dd39-4363-83cc-fedabd313e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-8 vs 9-13\n",
    "\n",
    "ordinal_val9= val_labels.copy()\n",
    "ordinal_val9 = ordinal_val9.values\n",
    "ordinal_val9 = np.where(ordinal_val9 < 9, 0, 1)\n",
    "\n",
    "ordinal_train9 = train_labels.copy()\n",
    "ordinal_train9 = ordinal_train9.values\n",
    "ordinal_train9 = np.where(ordinal_train9 < 9, 0, 1)\n",
    "\n",
    "\n",
    "bucket9_final_model = LogisticRegression()\n",
    "bucket9_final_model.set_params(**{'C': 1, 'max_iter': 400})\n",
    "bucket9_final_model.fit(train_features, ordinal_train9)\n",
    "\n",
    "bucket9_train_predict = bucket9_final_model.predict(train_features)\n",
    "bucket9_train_proba = bucket9_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][9] = bucket9_train_proba[idx][1] - final_ordinal_array[sample_idx][10]-final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]\n",
    "bucket9_train_accuracy = accuracy_score(ordinal_train9, bucket9_train_predict)\n",
    "bucket9_train_f1 = f1_score(ordinal_train9, bucket9_train_predict)\n",
    "train_accuracy.append(bucket9_train_accuracy)\n",
    "train_f1.append(bucket9_train_f1)\n",
    "\n",
    "bucket9_val_predict = bucket9_final_model.predict(final_val_features)\n",
    "bucket9_val_proba = bucket9_final_model.predict_proba(final_val_features)\n",
    "bucket9_val_accuracy = accuracy_score(ordinal_val9, bucket9_val_predict)\n",
    "bucket9_val_f1 = f1_score(ordinal_val9, bucket9_val_predict)\n",
    "val_accuracy.append(bucket9_val_accuracy)\n",
    "val_f1.append(bucket9_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][9] = bucket9_val_proba[idx][1] - final_ordinal_array[sample_idx][10]-final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d107bf6c-834c-46e4-b813-82a40ff17801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-7 vs 8-13\n",
    "\n",
    "ordinal_val8= val_labels.copy()\n",
    "ordinal_val8 = ordinal_val8.values\n",
    "ordinal_val8 = np.where(ordinal_val8 < 8, 0, 1)\n",
    "\n",
    "ordinal_train8 = train_labels.copy()\n",
    "ordinal_train8 = ordinal_train8.values\n",
    "ordinal_train8 = np.where(ordinal_train8 < 8, 0, 1)\n",
    "\n",
    "\n",
    "bucket8_final_model = LogisticRegression()\n",
    "bucket8_final_model.set_params(**{'C': 10, 'max_iter': 100})\n",
    "bucket8_final_model.fit(train_features, ordinal_train8)\n",
    "\n",
    "bucket8_train_predict = bucket8_final_model.predict(train_features)\n",
    "bucket8_train_proba = bucket8_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][8] = bucket8_train_proba[idx][1] - final_ordinal_array[sample_idx][9]-final_ordinal_array[sample_idx][10]-final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]\n",
    "bucket8_train_accuracy = accuracy_score(ordinal_train8, bucket8_train_predict)\n",
    "bucket8_train_f1 = f1_score(ordinal_train8, bucket8_train_predict)\n",
    "train_accuracy.append(bucket8_train_accuracy)\n",
    "train_f1.append(bucket8_train_f1)\n",
    "\n",
    "bucket8_val_predict = bucket8_final_model.predict(final_val_features)\n",
    "bucket8_val_proba = bucket8_final_model.predict_proba(final_val_features)\n",
    "bucket8_val_accuracy = accuracy_score(ordinal_val8, bucket8_val_predict)\n",
    "bucket8_val_f1 = f1_score(ordinal_val8, bucket8_val_predict)\n",
    "val_accuracy.append(bucket8_val_accuracy)\n",
    "val_f1.append(bucket8_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][8] = bucket8_train_proba[idx][1] - final_ordinal_array[sample_idx][9]-final_ordinal_array[sample_idx][10]-final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "485cf9e3-f981-4f13-95e3-30b3a22bcb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-6 vs 7-13 (from the label of 7)\n",
    "\n",
    "ordinal_val7= val_labels.copy()\n",
    "ordinal_val7 = ordinal_val7.values\n",
    "ordinal_val7 = np.where(ordinal_val8 < 7, 0, 1)\n",
    "\n",
    "ordinal_train7 = train_labels.copy()\n",
    "ordinal_train7 = ordinal_train7.values\n",
    "ordinal_train7 = np.where(ordinal_train7 < 7, 0, 1)\n",
    "\n",
    "\n",
    "bucket7_final_model = LogisticRegression()\n",
    "bucket7_final_model.set_params(**{'C': 10, 'max_iter': 400})\n",
    "bucket7_final_model.fit(train_features, ordinal_train7)\n",
    "\n",
    "bucket7_train_predict = bucket7_final_model.predict(train_features)\n",
    "bucket7_train_proba = bucket7_final_model.predict_proba(train_features)\n",
    "for idx, sample_idx in enumerate(train_features.index):\n",
    "    final_ordinal_array[sample_idx][7] = bucket7_train_proba[idx][1] - final_ordinal_array[sample_idx][8]-final_ordinal_array[sample_idx][9]-final_ordinal_array[sample_idx][10]-final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]\n",
    "bucket7_train_accuracy = accuracy_score(ordinal_train7, bucket7_train_predict)\n",
    "bucket7_train_f1 = f1_score(ordinal_train7, bucket7_train_predict)\n",
    "train_accuracy.append(bucket7_train_accuracy)\n",
    "train_f1.append(bucket7_train_f1)\n",
    "\n",
    "bucket7_val_predict = bucket7_final_model.predict(final_val_features)\n",
    "bucket7_val_proba = bucket7_final_model.predict_proba(final_val_features)\n",
    "bucket7_val_accuracy = accuracy_score(ordinal_val7, bucket7_val_predict)\n",
    "bucket7_val_f1 = f1_score(ordinal_val7, bucket7_val_predict)\n",
    "val_accuracy.append(bucket7_val_accuracy)\n",
    "val_f1.append(bucket7_val_f1)\n",
    "for idx, sample_idx in enumerate(val_features.index):\n",
    "    final_ordinal_array[sample_idx][7] = bucket7_train_proba[idx][1] - final_ordinal_array[sample_idx][8]-final_ordinal_array[sample_idx][9]-final_ordinal_array[sample_idx][10]-final_ordinal_array[sample_idx][11]-final_ordinal_array[sample_idx][12]-final_ordinal_array[sample_idx][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af382def-5598-499d-b4ff-0eea81cb162d",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd1f7fee-5f28-4259-9023-452386356912",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = np.zeros(len(train_features))\n",
    "val_predictions = np.zeros(len(val_features))\n",
    "\n",
    "for idx, train_idx in enumerate(train_features.index):\n",
    "    prediction = np.argmax(final_ordinal_array[train_idx])\n",
    "    train_predictions[idx] = prediction\n",
    "    \n",
    "for idx, val_idx in enumerate(val_features.index):\n",
    "    prediction = np.argmax(final_ordinal_array[val_idx])\n",
    "    val_predictions[idx] = prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a28907b1-7bc3-4f2e-a4a5-07572ff96ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.3984156570363467\n",
      "Validation f1 score: 0.05066362503131241\n"
     ]
    }
   ],
   "source": [
    "#Validation accuracy and F1 score\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "val_f1 = f1_score(val_labels, val_predictions, average = 'macro')\n",
    "\n",
    "print(\"Validation accuracy: \" + str(val_accuracy))\n",
    "print(\"Validation f1 score: \" + str(val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5468fa85-4893-4017-aced-96ee3f996cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.41838518000699054\n",
      "Train f1 score: 0.41838518000699054\n"
     ]
    }
   ],
   "source": [
    "#Training accuracy and f1 score \n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "train_f1  = f1_score(train_labels, train_predictions, average = 'micro')\n",
    "\n",
    "print(\"Train accuracy: \" + str(train_accuracy))\n",
    "print(\"Train f1 score: \" + str(train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0c449ee7-d0b3-42a1-ba11-09087a91f788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_ordinal_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0341382c-6cb5-4b89-a945-261bd40a1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of true target variable and predictions\n",
    "\n",
    "def plot_distribution(sample_idx, target_df, ordinal_probability_array):\n",
    "    one_hot_df = pd.get_dummies(target_df.Q24_Encoded) #drop \n",
    "    target = np.array(one_hot_df.iloc[idx])\n",
    "    target = target[:-1]\n",
    "    prediction = ordinal_probability_array[sample_idx]\n",
    "    \n",
    "    labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "    \n",
    "    x = np.arange(len(labels)) #label locations\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, target, width, label = \"Target\")\n",
    "    rects2 = ax.bar(x + width/2, prediction, width, label = 'Predictions')\n",
    "    \n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_title(\"Probability vs label of sample index \" + str(sample_idx))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15291d70-7537-40ed-8f26-2c95f0827961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(592, Q24_Encoded, final_ordinal_array) #Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "66171c56-228f-4a16-9b75-1c23a6f32df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(2968, Q24_Encoded, final_ordinal_array) #train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ec431-db89-4ca6-9564-0a2c8b6aa9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
